[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "XSTK",
    "section": "",
    "text": "$$\n\\def\\argmax{\\operatorname*{argmax}}\n\\def\\argmin{\\operatorname*{argmin}}\n\\def\\as{\\textrm{a.s.}}\n\\def\\Ber{\\text{Ber}}\n\\def\\Beta#1#2{\\text{Beta}\\left(#1,#2\\right)}\n\\def\\Bin{\\text{Bin}}\n\\def\\Geom{\\text{Geom}}\n\\def\\Unif{\\text{Unif}}\n\\def\\E{\\mathbb{E}}\n\\def\\iid{\\stackrel{iid}{\\sim}}\n\\def\\is{\\coloneqq}\n\\def\\Gaus#1#2{\\mathcal{N}\\left(#1,#2\\right)}\n\\def\\indicator#1{\\mathbb{1}\\{#1\\}}\n\\def\\p{\\vec{p}}\n\\def\\P{\\mathbb{P}}\n\\def\\Poiss{\\text{Poiss}}\n\\def\\R{\\mathbb{R}}\n\\def\\V{\\mathbb{V}}\n\\def\\N{\\mathbb{Z}_+}\n\\def\\TV{\\textrm{TV}}\n\\def\\KL{\\textrm{KL}}\n\\def\\vec#1{\\boldsymbol{#1}}\n\\def\\toapd{\\xrightarrow[n\\to\\infty]{\\as/\\P/(d)}}\n\\def\\toprob{\\xrightarrow[n\\to\\infty]{\\P}}\n\\def\\tosure{\\xrightarrow[n\\to\\infty]{\\as}}\n\\def\\todist{\\xrightarrow[n\\to\\infty]{(d)}}\n$$\n\n\n\n\nLời nói đầu\nXác suất thống kê là nền tảng giúp ích cho việc phân tích dữ liệu, tổ chức thực hành thí nghiệm, chạy các mô hình giả lập, giải các bài toán tìm nghiệm tối ưu, nghiên cứu và ứng dụng học máy.\nMôn “xác suất” tôi đã học những kiến thức cơ bản vài lần, tính ra là ở cấp 3, trong đại học, và gần đây là học trực tuyến. Môn “thống kê” tôi chưa học được cho ra bài bản lần nào, mấy tháng đầu năm 2022 có thử sức học trực tuyến nhưng đầu tư thời gian không đủ nên thi rớt thảm hại.\nLần này nhất quyết học lại môn thống kê một cách nghiêm túc hơn, tôi tóm tắt lại kiến thức xác suất thống kê bằng tiếng Việt, mặc dù tài liệu học hầu hết là tiếng Anh, tiếng Nhật. Hy vọng tiếng mẹ đẻ sẽ giúp tôi hiểu rõ hơn các vấn đề, và trau dồi vốn từ vựng để chia sẻ kiến thức với các đồng nghiệp và bạn bè người Việt.\nĐộng cơ của việc học xác suất thống kê của tôi là để hiểu rõ hơn các lý thuyết căn bản trong ngành học máy và trí tuệ nhân tạo và áp dụng vào thực tiễn một cách đúng đắn, an toàn và công bằng hơn.\nMục tiêu cụ thể trước mắt tôi đặt ra là học hiểu và lấy được chứng chỉ hoàn thành khoá học Fundamentals of Statistics của Philippe Rigollet (2022), giáo sư đại học MIT dạy trên nền tảng trực tuyến edX. Tài liệu tham khảo là quyển “All of Statistics” của Wasserman (2004), cũng chính là tài liệu tham khảo của khoá học nêu trên.\nMôn xác suất nghiên cứu cách suy luận ra các đặc tính của tập dữ liệu sẽ được tạo ra từ một nguyên lý, quy trình sản sinh dữ liệu. Ngược lại, môn thống kê nghiên cứu cách dự đoán đặc tính của một quy trình sản sinh dữ liệu từ tập dữ liệu về hiện tượng đã phát sinh và được quan sát. H 1 minh hoạ quan hệ giữa “xác suất” và “thống kê”.\n\n\n\n\n\nflowchart LR\n  A((Nguyên lý,\\n Quy trình))\n  B((Hiện tượng,\\n Quan trắc))\n  A-- Xác suất -->B\n  B-- Thống kê --> A\n\n\n\n\n\nHình 1: Xác suất và thống kê.\n\n\n\n\nPhân tích, khai thác dữ liệu, học máy và khoa học dữ liệu là những tên gọi khác của thống kê, tùy theo bối cảnh và trào lưu. Một số ứng dụng cụ thể của thống kê là tính toán hồi quy, mật độ, phân loại và giả lập.\nTài liệu này không đi sâu vào các chứng minh chi tiết, nhưng sẽ cố gắng ghi rõ các công thức và định nghĩa. Thuật ngữ chuyên môn trong tài liệu này chắc chắn có nhiều chỗ không chuẩn chỉnh do vốn tiếng Việt và kiến thức hạn chế của tác giả. Xin vui lòng góp ý tại GitHub issues.\nTài liệu này được viết bằng các công cụ là Quarto và VSCode. Truy cập trực tuyến tại xstk . \\({}\\)\n\n\n\n\nPhilippe Rigollet, Tyler Maunu, Jan Christian Huetter. 2022. “Fundamentals of Statistics.” MITx. https://www.edx.org/course/fundamentals-of-statistics.\n\n\nWasserman, Larry. 2004. All of Statistics : A Concise Course in Statistical Inference. New York: Springer. https://archive.org/details/springer_10.1007-978-0-387-21736-9."
  },
  {
    "objectID": "notation.html",
    "href": "notation.html",
    "title": "Ký hiệu",
    "section": "",
    "text": "$$\n\\def\\argmax{\\operatorname*{argmax}}\n\\def\\argmin{\\operatorname*{argmin}}\n\\def\\as{\\textrm{a.s.}}\n\\def\\Ber{\\text{Ber}}\n\\def\\Beta#1#2{\\text{Beta}\\left(#1,#2\\right)}\n\\def\\Bin{\\text{Bin}}\n\\def\\Geom{\\text{Geom}}\n\\def\\Unif{\\text{Unif}}\n\\def\\E{\\mathbb{E}}\n\\def\\iid{\\stackrel{iid}{\\sim}}\n\\def\\is{\\coloneqq}\n\\def\\Gaus#1#2{\\mathcal{N}\\left(#1,#2\\right)}\n\\def\\indicator#1{\\mathbb{1}\\{#1\\}}\n\\def\\p{\\vec{p}}\n\\def\\P{\\mathbb{P}}\n\\def\\Poiss{\\text{Poiss}}\n\\def\\R{\\mathbb{R}}\n\\def\\V{\\mathbb{V}}\n\\def\\N{\\mathbb{Z}_+}\n\\def\\TV{\\textrm{TV}}\n\\def\\KL{\\textrm{KL}}\n\\def\\vec#1{\\boldsymbol{#1}}\n\\def\\toapd{\\xrightarrow[n\\to\\infty]{\\as/\\P/(d)}}\n\\def\\toprob{\\xrightarrow[n\\to\\infty]{\\P}}\n\\def\\tosure{\\xrightarrow[n\\to\\infty]{\\as}}\n\\def\\todist{\\xrightarrow[n\\to\\infty]{(d)}}\n$$\n\n\n\n\n\n\nKý hiệu\nÝ nghĩa\n\n\n\n\n\\(\\R\\)\nTập hợp số thực\n\n\n\\(f(\\alpha) \\propto g(\\alpha)\\)\n\\(f/g\\) không phụ thuộc \\(\\alpha\\)\n\n\n\\(\\Gaus{\\mu}{\\sigma^2}\\)\nphân phối chuẩn tâm \\(\\mu\\), lệch \\(|\\sigma|\\)"
  },
  {
    "objectID": "10-proba-intro.html#sự-kiện",
    "href": "10-proba-intro.html#sự-kiện",
    "title": "1  Xác suất",
    "section": "1.1 Sự kiện",
    "text": "1.1 Sự kiện\nKhông gian \\(\\Omega\\) là tập hợp chứa tất cả những hiện tượng \\(\\omega\\) có thể xảy ra từ một thí nghiệm. Các tập con của \\(\\Omega\\) là các sự kiện.\nVí dụ xem xét thí nghiệm tung một đồng xu đúng hai lần, quan sát đồng xu rớt xuống nằm ngửa (\\(H\\)) hay sấp (\\(T\\)), ta có \\(\\Omega = \\{HH, HT, TH, TT\\}\\) bao gồm 4 kết quả có thể xảy ra. Sự kiện lần tung đầu tiên ra mặt ngửa của đồng xu là tập hợp \\(\\{HH, HT\\}.\\)\nCho một sự kiện \\(A\\subseteq\\Omega\\), ta nói \\(A\\) xảy ra, hoặc \\(A\\) là đúng, nếu có một hiện tượng \\(\\omega\\in A\\) xảy ra. Sự kiện ngược lại với \\(A\\) là \\(A^c\\is\\Omega-A\\is \\{\\omega\\in\\Omega: \\omega\\notin A\\}\\), tức là “không xảy ra \\(A\\)”. Theo định nghĩa, rõ ràng \\(\\Omega\\) luôn luôn đúng, còn sự kiện rỗng \\(\\emptyset\\equiv\\Omega^c\\) luôn luôn sai. Cho thêm sự kiện \\(B\\), ta có \\(A\\cup B\\) là sự kiện “\\(A\\) hoặc \\(B\\) ít nhất một việc xảy ra”, còn \\(AB\\is A\\cap B\\) là sự kiện “\\(A\\) và \\(B\\) đồng thời xảy ra”.\nChuỗi sự kiện \\(A_1, A_2, \\ldots\\) được gọi là phân ly nếu \\(A_i A_j\\equiv\\emptyset\\) với mọi \\(i\\neq j\\). Khi đó nếu \\(A_1\\cup A_2\\cup\\cdots\\equiv C\\) thì ta nói \\(A_1, A_2, \\ldots\\) là một cách phân hoạch sự kiện \\(C\\).\n\nĐịnh nghĩa 1.1 (Biến ngẫu nhiên, random variable) là một quy tắc ánh xạ \\(X: \\Omega\\to\\R\\) gán cho mỗi hiện tượng \\(\\omega\\) trong không gian \\(\\Omega\\) một số thực \\(X(\\omega).\\)"
  },
  {
    "objectID": "10-proba-intro.html#xác-suất",
    "href": "10-proba-intro.html#xác-suất",
    "title": "1  Xác suất",
    "section": "1.2 Xác suất",
    "text": "1.2 Xác suất\nNếu một xạ ảnh \\(\\P\\) từ không gian các sự kiện \\(A\\subseteq\\Omega\\) lên tập hợp số thực \\(\\R\\) thỏa mãn các điều kiện:\n\n\\(\\P(A)\\geq 0\\quad\\forall A\\)\n\\(\\P(\\Omega) = 1\\)\nNếu chuỗi \\(A_1, A_2, \\ldots\\) phân hoạch \\(C\\) thì \\(\\P(A_1) + \\P(A_2) + \\cdots = \\P(C)\\)\n\nthì ta gọi \\(\\P\\) là một phân phối xác suất hoặc độ đo xác suất.\nCó hai cách cắt nghĩa khái niệm xác suất là tần suất và niềm tin. Theo cách hiểu tần suất thì \\(\\P(A)\\) chính là tỷ lệ số lần sự kiện \\(A\\) xảy ra nếu ta thực hiện thí nghiệm vô số lần. Còn theo cách hiểu niềm tin thì \\(\\P(A)\\) là thước đo mức độ mà một quan sát viên tin tưởng rằng hiện tượng \\(A\\) sẽ xảy ra.\n\nĐịnh nghĩa 1.2 (Hàm khối xác suất, probability mass function) Với biến rời rạc \\(X:\\Omega\\to D,\\) \\(D=\\{x_1, x_2, \\ldots\\}\\) đếm được, thì ta có thể gán xác suất \\(\\P(x_i) = p_i\\geq 0,\\forall i=1,2,\\ldots\\) sao cho \\(\\sum_i p_i \\equiv 1.\\)\n\n\nĐịnh nghĩa 1.3 (Hàm phân phối tích lũy, cumulative distribution function) là hàm tăng đơn điệu và liên tục bên phải \\(F:\\R\\to[0,1], F(x)\\is\\P(X\\leq x)\\) với biến \\(X:\\Omega\\to \\R.\\)\n\n\nĐịnh nghĩa 1.4 (Hàm mật độ xác suất, probability density function) là \\(f(x) = F^\\prime(x)\\) với \\(F(x)\\is\\P(X\\leq x)\\) là phân phối tích lũy của biến \\(X:\\Omega\\to \\R.\\) Mật độ xác suất là không âm và có tích phân toàn phần bằng \\(1\\).\n\n\nĐịnh nghĩa 1.5 (Điểm cắt) Biến \\(X\\) tuân theo phân phối tích lũy \\(F\\) có điểm cắt tại mức \\(1-\\alpha\\) là \\(q_\\alpha\\is F^{-1}(1-\\alpha).\\)"
  },
  {
    "objectID": "10-proba-intro.html#phụ-thuộc",
    "href": "10-proba-intro.html#phụ-thuộc",
    "title": "1  Xác suất",
    "section": "1.3 Phụ thuộc",
    "text": "1.3 Phụ thuộc\n\nĐịnh nghĩa 1.6 (Xác suất hợp) Ký hiệu \\(\\P(A, B)\\) hoặc \\(\\P(A\\cap B)\\) chỉ xác suất sự kiện \\(A\\) và sự kiện \\(B\\) đồng thời xảy ra.\n\n\nĐịnh nghĩa 1.7 (Độc lập) Hai sự kiện \\(A\\) và \\(B\\) là độc lập nếu \\(\\P(A,B)\\equiv \\P(A)\\P(B)\\).\nHai biến \\(X\\) và \\(Y\\) là độc lập nếu hai sự kiện \\(X\\leq x\\) và \\(Y\\leq y\\) là độc lập đối với mọi \\(x,y\\).\n\n\nĐịnh nghĩa 1.8 (IID) Các biến ngẫu nhiên \\(X_1, X_2, \\ldotp\\) được gọi là iid (“independent and identically distributed”, “độc lập và phân phối giống nhau”) nếu chúng cùng tuân theo duy nhất (identical) một phân phối xác suất, và từng cặp biến là độc lập (independent) với nhau. Dùng biến \\(X\\) để thể hiện phân phối xác suất chung đó, ta viết \\[\nX_1,\\ldots,X_n \\iid X.\n\\]\n\n\nĐịnh nghĩa 1.9 (Xác suất có điều kiện) Ký hiệu \\(\\P(A|B)\\) hoặc \\(\\P_B(A)\\) chỉ xác suất của sự kiện \\(A\\), khi biết sự kiện \\(B\\) đã xảy ra,\n\\[\n\\P(A|B) = \\frac{\\P(A,B)}{\\P(B)}.\n\\]\n\n\nĐịnh lý 1.1 (Định lý Bayes) \\[\n\\P(A|B) = \\frac{\\P(B|A)\\P(A)}{\\P(B)}\n= \\frac{\\P(B|A)\\P(A)}{\\P(B|A)\\P(A) + \\P(B|A^c)\\P(A^c)}\n.\n\\]"
  },
  {
    "objectID": "10-proba-intro.html#đặc-trưng",
    "href": "10-proba-intro.html#đặc-trưng",
    "title": "1  Xác suất",
    "section": "1.4 Đặc trưng",
    "text": "1.4 Đặc trưng\n\nĐịnh nghĩa 1.10 (Trung bình) Trung bình, hay giá trị kỳ vọng của biến X là\n\\[\n\\E[X]\\is\n\\int x dF(x)\n\\is\n\\begin{cases}\n\\sum_x x p(x) & \\textrm{ if } X \\textrm{ is discrete}\\\\\n\\int x f(x) dx & \\textrm{ if } X \\textrm{ is continuous}.\n\\end{cases}\n\\]\n\nNếu giá trị \\(\\int |x| dF(x) < \\infty\\) ta nói là \\(\\E[X]\\) “tồn tại” (well-defined).\nTa có \\[\n\\E[X+Y] \\equiv \\E[X] + E[Y].\n\\]\n\nĐịnh nghĩa 1.11 (Hiệp phương sai) \\[\n\\begin{split}\n\\textrm{Cov}[X,Y] &\\is \\E[(X-\\E[X])(Y-\\E[Y])] \\\\\n&\\equiv \\E[XY] - \\E[X]\\E[Y]\n\\end{split}\n\\]\n\nNếu \\(X\\) và \\(Y\\) độc lập thì \\(\\textrm{Cov}[X,Y] = 0\\).\n\nĐịnh nghĩa 1.12 (Phương sai) Phương sai, hay phân tán (variance) là \\[\n\\V[X]\\is\\textrm{Cov}[X,X]\\equiv\\E[X^2]-\\E^2[X].\n\\]\n\nTa có \\[\n\\V[X+Y] \\equiv \\V[X]+\\V[Y] + 2\\textrm{Cov}[X,Y].\n\\]\n\nĐịnh nghĩa 1.13 (Tích suất) Tích suất (moment) thể hiện trọng tâm, độ phân tán, hay độ lệch của phân phối. Tích suất bậc \\(n\\) của biến \\(X\\) với mật độ \\(f(x)\\) là:\n\n\\[\n\\E[X^n]\\is \\int x^n f(x) dx\n\\]\n\nĐịnh nghĩa 1.14 (Hàm tạo tích suất) “Moment generation function (MGF)” của biến \\(X\\) là \\[\n\\psi_X(t)\\is\\E[e^{tX}], t\\in\\R.\n\\]\n\nNếu MGF “tồn tại” lân cận \\(0\\) thì đạo hàm cấp \\(k\\) của \\(\\psi\\) tại \\(0\\) chính là: \\[\n\\psi_X^{(k)}(0)\\equiv \\E[X^k].\n\\]"
  },
  {
    "objectID": "20-distributions.html#phân-phối-bernoulli",
    "href": "20-distributions.html#phân-phối-bernoulli",
    "title": "2  Phân phối",
    "section": "2.1 Phân phối Bernoulli",
    "text": "2.1 Phân phối Bernoulli\n\nĐịnh nghĩa 2.1 (Bernoulli distribution) \\(X\\sim\\Ber(p)\\) có \\[\n\\P(X=1) = p = 1-\\P(X=0)\n\\] và \\(\\E[X] = p, \\V[X] = p(1-p)\\)."
  },
  {
    "objectID": "20-distributions.html#phân-phối-nhị-thức",
    "href": "20-distributions.html#phân-phối-nhị-thức",
    "title": "2  Phân phối",
    "section": "2.2 Phân phối nhị thức",
    "text": "2.2 Phân phối nhị thức\n\nĐịnh nghĩa 2.2 (Binomial distribution) \\(K\\sim\\Bin(n, p)\\) với \\(n\\in\\N, p\\in(0,1)\\) mô tả tổng số lần thành công của \\(n\\) thí nghiệm độc lập \\(K_1,\\ldots,K_n \\iid \\Ber(p).\\) Ta có \\[\n\\P(K=k) = \\binom{n}{k}p^{k}(1-p)^{n-k}\n\\] và \\(\\E[K] = np, \\V[K] = np(1-p)\\)."
  },
  {
    "objectID": "20-distributions.html#phân-phối-poisson",
    "href": "20-distributions.html#phân-phối-poisson",
    "title": "2  Phân phối",
    "section": "2.3 Phân phối Poisson",
    "text": "2.3 Phân phối Poisson\n\nĐịnh nghĩa 2.3 (Phân phối Poisson) \\(K\\sim\\Poiss(\\lambda),\\) \\(\\lambda > 0\\) cố định, có \\[\n\\P(K=k) = e^{-\\lambda}\n\\frac{\\lambda^k}{k!},\n\\] \\(k=0,1,2,\\ldots\\) là số lần phát sinh sự kiện trong một giới hạn cố định, các sự kiện phát sinh độc lập. \\[\\E[K] = \\V[K] = \\lambda\n.\\]\n\nKhi \\(n\\) đủ lớn và \\(p\\) đủ nhỏ thì \\(\\Poiss(np)\\) gần với \\(\\Bin(n,p)\\)."
  },
  {
    "objectID": "20-distributions.html#phân-phối-hình-học",
    "href": "20-distributions.html#phân-phối-hình-học",
    "title": "2  Phân phối",
    "section": "2.4 Phân phối hình học",
    "text": "2.4 Phân phối hình học\n\nĐịnh nghĩa 2.4 (Geometric distribution) \\(K\\sim\\Geom(p), p \\in (0,1)\\) có \\[\n\\P(K=k)=p(1-p)^{k-1}, k=1,2,\\ldots\n\\] là xác suất thành công đầu tiên xảy ra sau đúng \\(k\\) lần thực nghiệm \\(\\Ber(k).\\) \\[\\E[K]=1/p,\\V[K]=(1-p)/p^2.\\]"
  },
  {
    "objectID": "20-distributions.html#phân-phối-liên-tục",
    "href": "20-distributions.html#phân-phối-liên-tục",
    "title": "2  Phân phối",
    "section": "2.5 Phân phối liên tục",
    "text": "2.5 Phân phối liên tục"
  },
  {
    "objectID": "20-distributions.html#phân-phối-đều",
    "href": "20-distributions.html#phân-phối-đều",
    "title": "2  Phân phối",
    "section": "2.6 Phân phối đều",
    "text": "2.6 Phân phối đều\n\nĐịnh nghĩa 2.5 (Uniform distribution) \\(X\\sim\\Unif[a,b]\\) có mật độ \\[\nf(x)\\is\n\\frac{x-a}{b-a}\n\\textrm{ for }\nx\\in[a,b]\n\\] và \\[\\E[X] = \\frac{a+b}{2}, \\V[X]=\\frac{(b-a)^2}{12}.\\]\n\nNếu biến \\(X\\) có cdf \\(F\\) (ĐN 1.3) khả nghịch thì \\(F(X)\\sim\\Unif[0,1].\\)"
  },
  {
    "objectID": "20-distributions.html#phân-phối-mũ",
    "href": "20-distributions.html#phân-phối-mũ",
    "title": "2  Phân phối",
    "section": "2.7 Phân phối mũ",
    "text": "2.7 Phân phối mũ\n\nĐịnh nghĩa 2.6 (Exponential distribution) \\(X\\sim\\text{Exp}(\\lambda)\\) có \\[\nf(x)={\\lambda}e^{-\\lambda x},x\\in\\R_+,\n\\] \\(x\\) ước lượng khoảng cách giữa hai lần phát sinh sự kiện trong quá trình \\(\\Poiss(\\lambda).\\) \\[\\E[X]=1/\\lambda,\\V[X]=1/\\lambda^2.\\]"
  },
  {
    "objectID": "20-distributions.html#phân-phối-chuẩn",
    "href": "20-distributions.html#phân-phối-chuẩn",
    "title": "2  Phân phối",
    "section": "2.8 Phân phối chuẩn",
    "text": "2.8 Phân phối chuẩn\n\nĐịnh nghĩa 2.7 (Gaussian Distribution) \\(X\\sim\\Gaus{\\mu}{\\sigma^2}\\) có mật độ \\[\nf(x) =\n\\frac{1}{\\sqrt{\\pi 2\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\nx\\in\\R\n\\] và \\(\\E[X]=\\mu,\\V[X]=\\sigma^2\\).\n\n\nĐịnh lý 2.1 (Tổng của các phân phối chuẩn) Nếu \\(X_i \\sim\\Gaus{\\mu_i}{\\sigma_i^2} (i=1,\\ldots,n)\\) thì\n\\[\\sum_{i=1}^n X_i\\sim\n\\Gaus{\\sum_{i=1}^n \\mu_i}{\\sum_{i=1}^n \\sigma_i^2}\n.\\]\n\n\nĐịnh nghĩa 2.8 (Vector phân phối chuẩn) Nếu mọi tổ hợp tuyến tính các yếu tố của vector \\(\\boldsymbol{v}\\) đều thuộc phân phối chuẩn 1 biến thì \\(\\boldsymbol{v}\\) được gọi là một vector phân phối chuẩn."
  },
  {
    "objectID": "20-distributions.html#phân-phối-chi2",
    "href": "20-distributions.html#phân-phối-chi2",
    "title": "2  Phân phối",
    "section": "2.9 Phân phối \\(\\chi^2\\)",
    "text": "2.9 Phân phối \\(\\chi^2\\)\n\nĐịnh nghĩa 2.9 (Phân phối \\(\\chi^2\\)) \\(X\\sim\\chi_k^2\\) là tổng bình phương của \\(X_1,\\ldots,X_k\\iid\\Gaus{0}{1}\\)\n\\[\nX \\is \\sum_{i=0}^k X_i^2\n\\]\nvà có \\(\\E[X]=k,\\V[X]=2k\\)."
  },
  {
    "objectID": "20-distributions.html#phân-phối-student",
    "href": "20-distributions.html#phân-phối-student",
    "title": "2  Phân phối",
    "section": "2.10 Phân phối Student",
    "text": "2.10 Phân phối Student\n\nĐịnh nghĩa 2.10 (Student’s T distribution) Nếu có \\(Z\\sim\\Gaus{0}{1}, V\\sim \\chi_k^2\\) độc lập với nhau thì\n\\[\nX \\is \\frac{Z}{\\sqrt{V/k}}\n\\]\ntuân theo phân phối Student’s \\(t_k\\)."
  },
  {
    "objectID": "20-distributions.html#phân-phối-beta",
    "href": "20-distributions.html#phân-phối-beta",
    "title": "2  Phân phối",
    "section": "2.11 Phân phối Beta",
    "text": "2.11 Phân phối Beta\n\nĐịnh nghĩa 2.11 (Beta distribution) \\(X\\sim\\Beta{\\alpha}{\\beta},\\) tham số \\(\\alpha>0,\\beta>0\\) có mật độ trên \\(x\\in [0,1]\\) là \\[\nf(x) = Cx^{\\alpha-1}(1-x)^{\\beta-1}\n,\n\\] \\(C=C(\\alpha,\\beta)\\) là hằng số chuẩn hóa.\n\nPhân phối Beta có đồ thị rất linh hoạt trên khoảng \\([0,1],\\) rất phù hợp để sử dụng làm xác suất tiền nghiệm (ĐN 7.1) cho một tham số xác suất \\(p\\in[0,1].\\)\nVí dụ \\(\\Unif[0,1] = \\Beta{1}{1}.\\)"
  },
  {
    "objectID": "20-distributions.html#phân-phối-gamma",
    "href": "20-distributions.html#phân-phối-gamma",
    "title": "2  Phân phối",
    "section": "2.12 Phân phối Gamma",
    "text": "2.12 Phân phối Gamma\n\nĐịnh nghĩa 2.12 (Gamma distribution) với tham số \\(q>0, \\lambda>0,\\) có mật độ là \\[\nf(x)\\is\\frac{\\lambda^q x^{q-1} e^{-\\lambda x}}{\\Gamma(q)}\n\\quad \\forall\nx\\in (0,\\infty)\n,\n\\] \\(\\Gamma\\) là hàm Euler Gamma."
  },
  {
    "objectID": "30-proba-converge.html#hội-tụ-xác-suất",
    "href": "30-proba-converge.html#hội-tụ-xác-suất",
    "title": "3  Hội tụ",
    "section": "3.1 Hội tụ xác suất",
    "text": "3.1 Hội tụ xác suất\nCho một chuỗi biến ngẫu nhiên \\(X_1,X_2,\\ldotp\\) và một biến ngẫu nhiên \\(X\\).\n\nĐịnh nghĩa 3.1 (Hội tụ gần tuyệt đối) \\[\nX_n \\tosure X \\iff\n\\P(\\{\\omega\\in\\Omega: X_n(\\omega)\\to X(\\omega)\\}) = 1.\n\\]\n\n\nĐịnh nghĩa 3.2 (Hội tụ theo xác suất) \\[\nX_n \\toprob X \\iff\n\\P(|X_n-X| >\\epsilon)\n\\xrightarrow[n\\to\\infty]{}\n0,\\quad\\forall\\epsilon>0.\n\\]\n\n\nĐịnh nghĩa 3.3 (Hội tụ theo phân phối) \\[\nX_n \\todist X \\iff\n\\P[X_n(x)\\leq x]\\xrightarrow[n\\to\\infty]{} \\P[X\\leq x]\n\\] tại mọi điểm \\(x\\) mà cdf của \\(X\\) liên tục.\n\n\nĐịnh nghĩa 3.4 (Hội tụ về chuẩn) (asymptotically normal) với phương sai \\(\\sigma^2\\) \\[\n\\frac{\\sqrt{n}}{|\\sigma|}\n\\left({X}_n-X\\right)\n\\todist\n\\Gaus{0}{1}.\n\\]"
  },
  {
    "objectID": "30-proba-converge.html#độ-mạnh",
    "href": "30-proba-converge.html#độ-mạnh",
    "title": "3  Hội tụ",
    "section": "3.2 Độ mạnh",
    "text": "3.2 Độ mạnh\n\nĐịnh lý 3.1 Xếp theo thứ tự từ mạnh đến yếu:\n\\[\nX_n \\tosure X \\implies\nX_n \\toprob X \\implies\nX_n \\todist X.\n\\]\nNếu \\(X_n \\todist X\\), và \\(X\\) có mật độ xác suất, thì \\(X_n \\toprob X\\).\nNếu chuỗi \\(X_n\\) có \\(\\E[X_n]\\xrightarrow[]{} \\mu\\) và \\(\\V[X_n]\\xrightarrow[]{} 0\\) thì \\(X_n\\xrightarrow[]{\\P} \\mu\\).\nNếu \\(X_n\\toprob X\\) thì \\(\\P(a\\leq X_n\\leq b) \\xrightarrow[n\\to\\infty]{} \\P(a\\leq X\\leq b)\\) với mọi khoảng \\([a,b]\\)."
  },
  {
    "objectID": "30-proba-converge.html#tổng-và-tích",
    "href": "30-proba-converge.html#tổng-và-tích",
    "title": "3  Hội tụ",
    "section": "3.3 Tổng và tích",
    "text": "3.3 Tổng và tích\n\nĐịnh lý 3.2 Nếu có hai chuỗi biến ngẫu nhiên \\(X_n, Y_n\\) hội tụ gần tuyệt đối hoặc hội tụ theo xác suất về \\(X, Y\\), thì tổng \\(X_n+Y_n\\) và tích \\(X_n Y_n\\) cũng hội tụ tương tự (gần tuyệt đối, hoặc theo xác suất) về tổng \\(X+Y\\) và tích \\(XY\\)."
  },
  {
    "objectID": "30-proba-converge.html#slutsky",
    "href": "30-proba-converge.html#slutsky",
    "title": "3  Hội tụ",
    "section": "3.4 Slutsky",
    "text": "3.4 Slutsky\n\nĐịnh lý 3.3 Hơn nữa, ở ĐL 3.2 nếu \\(Y_n \\xrightarrow[]{\\P} y\\), \\(y\\) là một số thực cố định thì có thể nới lỏng điều kiện đối với \\(X_n\\) thành hội tụ theo phân phối."
  },
  {
    "objectID": "30-proba-converge.html#ánh-xạ-liên-tục",
    "href": "30-proba-converge.html#ánh-xạ-liên-tục",
    "title": "3  Hội tụ",
    "section": "3.5 Ánh xạ liên tục",
    "text": "3.5 Ánh xạ liên tục\n\nĐịnh lý 3.4 (Continuous mapping) Nếu \\(X_n\\toapd X\\) thì đối với mọi hàm \\(f\\) liên tục:\n\n\\(f(X_n)\\toapd f(X)\\).\n\\(\\E[f(X_n)]\\xrightarrow[n\\to\\infty]{}\\E[f(X)]\\) nếu \\(f\\) còn bị chặn."
  },
  {
    "objectID": "30-proba-converge.html#đại-đa-số",
    "href": "30-proba-converge.html#đại-đa-số",
    "title": "3  Hội tụ",
    "section": "3.6 Đại đa số",
    "text": "3.6 Đại đa số\n\nĐịnh lý 3.5 (Law of Large Numbers, LLN) Cho \\(n\\) biến iid \\(X_1, X_2,\\ldotp,X_n\\iid X\\) có \\(\\E[X]<\\infty\\). Khi đó: \\[\\bar{X}_n\\is\\frac{1}{n}\\sum_{i=1}^n{X_i}\n\\xrightarrow[n\\to\\infty]{\\P,\\,\\as}\\E[X].\n\\]"
  },
  {
    "objectID": "30-proba-converge.html#hội-tụ-trung-tâm",
    "href": "30-proba-converge.html#hội-tụ-trung-tâm",
    "title": "3  Hội tụ",
    "section": "3.7 Hội tụ trung tâm",
    "text": "3.7 Hội tụ trung tâm\n\nĐịnh lý 3.6 (Central Limit Theorem, CLT) Giả sử thêm là \\(\\V[X_i]=\\sigma^2<\\infty\\). Khi đó \\[\n\\sqrt{n}\n\\left(\n\\frac{\\bar{X}_n-\\mu}{|\\sigma|}\n\\right)\n\\todist\n\\Gaus{0}{1}.\n\\]"
  },
  {
    "objectID": "30-proba-converge.html#bất-đẳng-thức-hoefding",
    "href": "30-proba-converge.html#bất-đẳng-thức-hoefding",
    "title": "3  Hội tụ",
    "section": "3.8 Bất đẳng thức Hoefding",
    "text": "3.8 Bất đẳng thức Hoefding\n\nĐịnh lý 3.7 Nếu có một khoảng cố định \\([a,b]\\) gần như tuyệt đối (almost surely) chứa các biến \\(X_i (i=1,2,\\ldots,n)\\) thì\n\\[\n\\P[|\\bar{X}_n-\\mu|\\geq\\epsilon]\\leq\n2e^{-\\frac{2n\\epsilon^2}{(b-a)^2}},\\quad\\forall\\epsilon>0.\n\\]"
  },
  {
    "objectID": "30-proba-converge.html#phương-pháp-delta",
    "href": "30-proba-converge.html#phương-pháp-delta",
    "title": "3  Hội tụ",
    "section": "3.9 Phương pháp Delta",
    "text": "3.9 Phương pháp Delta\n\nĐịnh lý 3.8 (Phương pháp Delta) Giả sử chuỗi \\((\\theta_n)_{n\\geq 1}\\) chuẩn tiến (ĐN 3.4) với phương sai \\(\\sigma^2\\) về một điểm \\(\\theta\\in\\R\\). Giả sử \\(g:\\R\\to\\R\\) có vi phân \\(g^\\prime\\) liên tục, \\(\\neq 0\\) tại \\(\\theta\\). Khi đó, \\[\n\\frac{\\sqrt{n}}{|\\sigma|}\n\\left(\\frac{g(\\theta_n)-g(\\theta)}\n{g^\\prime(\\theta)}\\right)\n\\todist\n\\Gaus{0}{1}\n\\]\n\n\nĐịnh lý 3.9 (Phương pháp Delta nhiều biến) Giả sử chuỗi \\((\\vec{\\theta}_n)_{n\\geq 1}\\) chuẩn tiến với phương sai \\(\\Sigma(\\vec{\\theta})\\) về \\(\\vec{\\theta}\\in\\R^d:\\) \\[\n\\sqrt{n}(\\vec{\\theta}_n-\\vec{\\theta})\n\\todist\\Gaus_d(\\vec{0},\\Sigma).\n\\]\nGiả sử \\(g:\\R^d\\to\\R^k\\) có vi phân \\(\\nabla g\\) liên tục \\((k<d)\\). Khi đó, \\[\n\\sqrt{n}\\left(g(\\vec{\\theta}_n)-g(\\vec{\\theta})\\right)\n\\todist\\Gaus_k\n\\left(\\vec{0}, \\Gamma\\right)\n,\n\\]\nvới \\(\\Gamma\\is\\nabla g(\\vec{\\theta})^T \\Sigma \\nabla g(\\vec{\\theta}).\\) Nếu \\(\\Sigma\\) khả nghịch, \\(\\nabla g\\) rank \\(k\\) thì \\(\\Gamma\\) khả nghịch, \\[\n\\sqrt{n}\\Gamma^{-1/2}\\left(g(\\vec{\\theta}_n)-g(\\vec{\\theta})\\right)\n\\todist\\Gaus_k\\left(\\vec{0}, \\vec{I}_k\\right)\n,\n\\] \\[\n{n}\\Gamma^{-1}\\left(g(\\vec{\\theta}_n)-g(\\vec{\\theta})\\right)^2\n\\todist\\chi_k^2\n.\n\\]"
  },
  {
    "objectID": "40-stat-intro.html#mô-hình",
    "href": "40-stat-intro.html#mô-hình",
    "title": "4  Thống kê",
    "section": "4.1 Mô hình",
    "text": "4.1 Mô hình\nTrên không gian đo được \\(E\\subseteq\\R\\) ta quan sát các mẫu \\(X_1,\\ldots,X_n\\iid\\P\\). Với tập tham số \\(\\Theta\\) ta xây dựng bộ độ đo xác suất \\((\\P_\\theta)_{\\theta\\in\\Theta}\\) để mô phỏng \\(\\P\\) .\nNếu tồn tại \\(\\theta\\in\\Theta\\) để \\(\\P_\\theta\\equiv\\P\\) thì ta nói mô hình “hợp lệ” (well specified).\nNếu từ tập \\(\\Theta\\), ánh xạ \\(\\theta\\mapsto\\P_{\\theta}\\) là đơn ánh thì ta nói \\(\\theta\\) (hoặc \\(\\P_\\theta\\)) là “có thể xác định” (identifiable).\nNếu \\(\\Theta\\subseteq\\R^d\\) thì mô hình được nói có số biến hữu hạn (parametric model)."
  },
  {
    "objectID": "40-stat-intro.html#ước-lượng",
    "href": "40-stat-intro.html#ước-lượng",
    "title": "4  Thống kê",
    "section": "4.2 Ước lượng",
    "text": "4.2 Ước lượng\nThống kê lượng (statistic) \\(\\theta\\) là bất cứ hàm số nào có thể đo được (measurable function) trên tập dữ liệu đối tượng \\(X_i\\).\nĐánh giá (estimator) \\(\\theta_n\\) đối với mục tiêu thống kê \\(\\theta\\) là một thống kê khác không phụ thuộc vào \\(\\theta\\).\nĐánh giá được gọi là nhất quán (consistent) nếu nó hội tụ về mục tiêu (ĐN 3.2).\n\nĐịnh nghĩa 4.1 (Pivotal statistic) Một phân phối hay một ước lượng được gọi là pivotal nếu nó không phụ thuộc vào phân phối chưa biết và giá trị cụ thể của dữ liệu."
  },
  {
    "objectID": "40-stat-intro.html#sai-số",
    "href": "40-stat-intro.html#sai-số",
    "title": "4  Thống kê",
    "section": "4.3 Sai số",
    "text": "4.3 Sai số\n\nĐịnh nghĩa 4.2 (Độ lệch, bias) giữa đánh giá \\(\\theta_n\\) với mục tiêu \\(\\theta\\) là \\[\\textrm{bias}_{\\theta}({\\theta}_n) \\is \\E[\\theta_n] - \\theta.\\]\n\n\nĐịnh nghĩa 4.3 (Sai số bậc 2, quadratic risk, mean squared error) giữa đánh giá \\(\\theta_n\\) với mục tiêu \\(\\theta\\) là \\[\n\\textrm{MSE}(\\theta_n)\\is\\E[(\\theta_n-\\theta)^2]\n\\equiv\n\\textrm{bias}_{\\theta}(\\theta_n)^2\n+\n\\V[\\theta_n]\n\\] bao hàm cả độ lệch và độ nhiễu của đánh giá."
  },
  {
    "objectID": "40-stat-intro.html#khoảng-tin-cậy",
    "href": "40-stat-intro.html#khoảng-tin-cậy",
    "title": "4  Thống kê",
    "section": "4.4 Khoảng tin cậy",
    "text": "4.4 Khoảng tin cậy\nVới mô hình thống kê \\((E,(\\P_\\theta)_{\\theta\\in\\Theta})\\) xây dựng dựa trên quan sát \\(X_1,\\ldots,X_n\\), giả sử số \\(\\alpha\\in(0,1).\\) Khoảng tin cậy (confidence interval) cấp \\(1-\\alpha\\) đối với \\(\\theta\\) là một khoảng ngẫu nhiên \\(\\mathcal{I}\\) (phụ thuộc vào \\(X_1,\\ldots,X_n\\), không phụ thuộc vào \\(\\theta\\)), mà xác suất \\(\\mathcal{I}\\) có chứa \\(\\theta\\) là đủ cao: \\[\\P_\\theta[\\mathcal{I}\\ni\\theta]\\geq 1-\\alpha,\\quad\\forall\\theta\\in\\Theta.\\]\nNếu \\[\\lim_{n\\to\\infty}\\P_\\theta[\\mathcal{I}\\ni\\theta]\\geq 1-\\alpha,\\quad\\forall\\theta\\in\\Theta\\] thì ta gọi \\(\\mathcal{I}\\) là khoảng tin cậy tiệm cận cấp \\(1-\\alpha\\) đối với \\(\\theta\\)."
  },
  {
    "objectID": "40-stat-intro.html#định-lý-cơ-bản",
    "href": "40-stat-intro.html#định-lý-cơ-bản",
    "title": "4  Thống kê",
    "section": "4.5 Định lý cơ bản",
    "text": "4.5 Định lý cơ bản\n\nĐịnh nghĩa 4.4 (Empirical cdf) Với \\(X_1,\\ldots,X_n\\iid X,\\) ước lượng phân phối tích lũy (ĐN 1.3) của \\(X\\) là hàm tăng đơn điệu và liên tục bên phải \\[\nF_n:\\R\\to[0,1],\nF_n(t)\\is\n\\frac{1}{n}\n\\sum_{i=1}^n\\indicator{X_i\\leq t},\n\\] tức là tỷ lệ số biến \\(X_i\\leq t.\\)\n\nNếu xếp \\(X_1\\leq\\ldots\\leq X_n<X_{n+1}=\\infty\\) từ nhỏ đến lớn thì ta có \\[\nF(t) = \\frac{i}{n}\n\\, \\textrm{ for } t\\in[X_{i}, X_{i+1})\n\\quad\\forall i=1,\\ldots,n\n.\\]\nÁp dụng LLN lên biến \\(\\indicator{X<t}\\) ta có \\(F_n(t)\\tosure F(t)\\,\\forall t\\in\\R.\\)\n\nĐịnh lý 4.1 (Glivenko-Cantelli, Fundamental Theorem of Statistics) \\(F_n\\) hội tụ đồng đều (converge uniformly) lên \\(F.\\) \\[\n\\sup_{t\\in\\R}|F_n(t)-F(t)|\n\\tosure 0\n.\\] Nói cách khác \\(\\forall\\delta>0,\\forall\\epsilon>0:\\exists N:\\) \\[\nn>N \\implies\n\\P\\left(\n\\sup_{t\\in\\R}|F_n(t)-F(t)| < \\delta\n\\right)\n\\geq 1-\\epsilon\n.\n\\]\n\n\nĐịnh lý 4.2 (Donsker’s theorem) Nếu cdf \\(F\\) thật là liên tục thì\n\\[\n\\sqrt{n}\\sup_{t\\in\\R}\n|F_n(t)-F(t)|\n\\todist\nZ\\sim\n\\sup_{0\\leq x \\leq 1}|B(x)|\n,\\] với \\(Z\\) là phân phối của đỉnh giá trị tuyệt đối của Brownian bridge, và là phân phối pivotal(ĐN 4.1)."
  },
  {
    "objectID": "50-est-method.html#tổng-biến-động",
    "href": "50-est-method.html#tổng-biến-động",
    "title": "5  Ước lượng",
    "section": "5.1 Tổng biến động",
    "text": "5.1 Tổng biến động\n\n5.1.1 Khoảng cách\n\nĐịnh nghĩa 5.1 tổng biến động (total variation distance) giữa hai độ đo xác suất \\(\\P_\\theta\\) và \\(\\P_\\eta\\) là\n\\[\n\\TV(\\P_\\theta,\\P_{\\eta})\n=\n\\max_{A\\subset E}{\\mid\\P_\\theta(A)-\\P_\\eta(A)\\mid}.\n\\]\n\n\nĐịnh lý 5.1 (Công thức tính) Nếu tập mẫu \\(E\\) là rời rạc (discrete: countable or finite), xác suất \\(\\P_\\theta,\\P_{\\eta}\\) có hàm khối lần lượt là \\(p_\\theta,p_{\\eta}\\) thì \\[\n\\TV(\\P_\\theta,\\P_{\\eta}) =\n\\frac{1}{2}\n\\sum_{x\\in E}\\mid p_\\theta(x) - p_\\eta(x)\\mid.\n\\]\nNếu tập mẫu \\(E\\) là liên tục (continuous), xác suất \\(\\P_\\theta, \\P_{\\eta}\\) có mật độ lần lượt là \\(f_\\theta, f_{\\eta}\\) thì \\[\n\\TV(\\P_\\theta,\\P_{\\eta}) =\n\\frac{1}{2}\n\\int_{E}\\mid f_\\theta(x) - f_\\eta(x)\\mid dx.\n\\]"
  },
  {
    "objectID": "50-est-method.html#phân-kỳ-kl",
    "href": "50-est-method.html#phân-kỳ-kl",
    "title": "5  Ước lượng",
    "section": "5.2 Phân kỳ KL",
    "text": "5.2 Phân kỳ KL\n\n5.2.1 Phân kỳ KL\n\nĐịnh nghĩa 5.2 (KL divergence) Ký hiệu \\(f\\) là mật độ hoặc hàm khối xác suất:\n\\[\n\\KL(\\P_\\theta, \\P_\\eta) \\is\n\\E_\\theta\\left[ \\ln\\frac{f_\\theta(x)}{f_\\eta(x)} \\right]\n=\n\\E_\\theta\\left[ \\ln{f_\\theta(x)} \\right]\n-\n\\E_\\theta\\left[ \\ln{f_\\eta(x)} \\right]\n.\n\\]\n\n\n\n5.2.2 Đặc điểm\n\nProposition 5.1 Phân kỳ KL thỏa mãn 2/4 đặc điểm của “khoảng cách”:\n\n\\(\\KL(\\P_\\theta, \\P_\\eta) \\geq 0\\)\n\\(\\KL(\\P_\\theta, \\P_\\eta) \\equiv 0 \\iff \\P_\\theta \\equiv \\P_\\eta\\)."
  },
  {
    "objectID": "50-est-method.html#hợp-lý-cực-đại",
    "href": "50-est-method.html#hợp-lý-cực-đại",
    "title": "5  Ước lượng",
    "section": "5.3 Hợp lý cực đại",
    "text": "5.3 Hợp lý cực đại\n\nĐịnh nghĩa 5.3 (Hợp lý, Likelihood) \\[L_\\theta(x_1,\\ldots,x_n)\\is\n\\P_\\theta(X_1=x_1,\\ldots,X_n=x_n)\n=\n\\prod_{i=1}^n p_\\theta(X_i=x_i)\n.\\]\n\n\nĐịnh nghĩa 5.4 (Log likelihood) \\[\n\\ell_\\theta(x_1,\\ldots,x_n)\\is\n\\ln\nL_\\theta(x_1,\\ldots,x_n)\n=\n\\sum_{i=1}^n \\ln p_\\theta(X_i=x_i)\n.\n\\]\n\n\nĐịnh nghĩa 5.5 (Maximum Likelihood Estimator, MLE) \\[\n\\hat{\\theta}_n \\is\n\\argmax_\\theta\nL_\\theta(x_1,\\ldots,x_n)\n\\equiv\n\\argmax_\\theta\n\\ell_\\theta(x_1,\\ldots,x_n)\n.\n\\]"
  },
  {
    "objectID": "50-est-method.html#mix-model",
    "href": "50-est-method.html#mix-model",
    "title": "5  Ước lượng",
    "section": "5.4 Mix model",
    "text": "5.4 Mix model\n\nĐịnh nghĩa 5.6 Cho các mô hình gốc \\(X^{(k)}, k= 1,\\ldots,K,\\) lấy biến tiềm ẩn \\(Z\\) trên \\(\\{1,\\ldots,K\\}\\) làm trọng số, ta có mô hình hỗn hợp \\[\nX = \\sum_{k=1}^K\n\\P(Z=k) X^{(k)}\n.\n\\]\n\n\n5.4.1 Giải thuật EM\n\nĐịnh nghĩa 5.7 (Estimation Maximization) có thể tìm được tham số \\(\\theta\\) của mô hình hỗn hợp ĐN 5.6.\nGiả sử ta quan sát được \\(X_1=x_1, \\ldots, X_n=x_n\\). Gọi các trọng số tiềm ẩn tương ứng là \\(Z_1=z_1, \\ldots, Z_n=z_n.\\)\nSau khi khởi tạo \\(\\theta = \\theta_0\\) ngẫu nhiên, ta lặp lại 2 bước E, M như sau để cập nhật \\(\\theta_k, k=1,2,\\ldots\\) cho đến khi hội tụ.\n\nEstimate: Ước lượng \\(Z_i\\approx\\omega_i\\is\\E[Z|X_i=x_i, \\theta=\\theta_{k-1}], i=1,\\ldots,n.\\)\nMaximize: Thay \\(Z_i\\) bởi \\(\\omega_i\\) vào công thức likelihood để tối ưu MLE \\(\\theta = \\theta_k\\)"
  },
  {
    "objectID": "50-est-method.html#chuẩn-tính-của-mle",
    "href": "50-est-method.html#chuẩn-tính-của-mle",
    "title": "5  Ước lượng",
    "section": "5.5 Chuẩn tính của MLE",
    "text": "5.5 Chuẩn tính của MLE\n\nĐịnh nghĩa 5.8 (Thông tin Fisher, Fisher information) Giả sử log likelihood đối với một quan sát \\(X\\) theo mô hình \\(\\theta\\in\\R\\) là \\(\\ell=\\ell(\\theta)\\is\\ln L_1(X,\\theta), \\theta\\in\\Theta\\subset\\R.\\) Giả sử \\(\\ell(\\theta)\\) có đạo hàm bậc hai. Dưới một số điều kiện chuẩn, thông tin Fisher của mô hình được định nghĩa là\n\\[\nI(\\theta)\n\\is\n\\V_X\n\\left[\\frac{\\partial\\ell}{\\partial\\theta}\\right]\n= \\E_X\n\\left[\\left(\\frac{\\partial\\ell}{\\partial\\theta}\\right)^2\\right]\n= -\\E_X\n\\left[\\frac{\\partial^2\\ell}{\\partial\\theta^2}\\right]\n.\n\\]\nTrường hợp mô hình đa biến, \\(\\theta\\is(\\theta_1,\\ldots,\\theta_k)\\in\\R^k:\\) \\[\nH_{ij} \\is \\frac{\\partial^2\\ell}{\\partial\\theta_i\\partial\\theta_j},\n\\] \\[\nI(\\theta) \\is -\\E\n\\begin{bmatrix}\nH_{11} & \\cdots & H_{1k} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nH_{k1} & \\cdots & H_{kk} \\\\\n\\end{bmatrix}\n.\n\\]\n\n\nĐịnh lý 5.2 (MLE hội tụ) Gọi \\(\\theta^*\\in\\Theta\\) là tham số thật cần tìm. Giả sử\n\nCác tham số là indentifiable\nSupport của \\(\\P_\\theta\\) không phụ thuộc vào \\(\\theta\\) với mọi \\(\\theta\\in\\Theta\\)\n\\(\\theta^*\\) không nằm trên biên giới của \\(\\Theta\\)\nThông tin Fisher khả nghịch lân cận \\(\\theta^*\\)\nMột số điều kiện kỹ thuật khác\n\nKhi đó, chuỗi \\(\\hat{\\theta}_n^{MLE}\\) thỏa mãn:\n\\[\\hat{\\theta}_n^{MLE} \\xrightarrow[n\\to\\infty]{\\P_{\\theta^*}}\\theta^*\\] \\[\\sqrt{n I(\\theta^*)}\\left(\\hat{\\theta}_n^{MLE}-\\theta^*\\right)\n\\xrightarrow[n\\to\\infty]{(d)\\textrm{ w.r.t.}\\P_{\\theta^*}}\n\\Gaus{0}{1}.\\]\nTrường hợp mô hình đa biến, \\(\\theta\\in\\R^k:\\) \\[{n\n\\left(\\hat{\\theta}_n^{MLE}-\\theta^*\\right)^T\nI(\\theta^*)}\n\\left(\\hat{\\theta}_n^{MLE}-\\theta^*\\right)\n\\xrightarrow[n\\to\\infty]{(d)\\textrm{ w.r.t.}\\P_{\\theta^*}}\n\\chi_k^2.\\]\nChú ý là điều kiện số 2 dễ bị vi phạm, ví dụ \\(X_i\\iid\\Unif[0, \\theta]\\) mà lại cần tìm tham số \\(\\theta.\\)"
  },
  {
    "objectID": "50-est-method.html#m-estimatior",
    "href": "50-est-method.html#m-estimatior",
    "title": "5  Ước lượng",
    "section": "5.6 M-estimatior",
    "text": "5.6 M-estimatior\n\nĐịnh nghĩa 5.9 Với mục tiêu ước lượng thuộc tính \\(\\mu^*\\) của xác suất \\(\\P(X)\\), ta tìm một “hàm tổn thất” \\(\\rho(X,\\mu)\\) có giá trị kỳ vọng đạt cực tiểu tại \\(\\mu = \\mu^*:\\) \\[\n\\mathcal{Q}(\\mu)\n\\is \\E_{\\P}[\\rho(X,\\mu)]\n.\n\\]\nNếu quan sát được \\(X_1,\\ldots,X_n\\iid\\P(X),\\) ta ước lượng \\[\n\\mathcal{Q}(\\mu)\n\\approx\n\\mathcal{Q}_n(\\mu)\n\\is\n\\frac{1}{n} \\sum_{i=1}^n{\\rho(X_i,\\mu)}\n.\\]\nKhi đó \\(\\mu^*\\approx\\hat{\\mu}\\) với “M-estimator” \\(\\hat{\\mu}\\) là\n\\[\n\\hat{\\mu}\n\\is\\argmin_{\\mu}\n\\mathcal{Q}_n(\\mu)\n.\n\\]\n\nVí dụ,\n\nvới \\(\\rho(x,\\theta) = -\\ln p_\\theta(x)\\) ta có MLE để ước lượng tham số \\(\\theta^*\\) của mô hình \\(\\P\\)\nvới \\(\\vec x,\\vec\\mu\\in\\R^d\\), dùng \\(\\rho(\\vec x,\\vec\\mu) = \\|\\vec x-\\vec\\mu\\|^2\\) ta ước lượng được \\(\\vec\\mu^*=\\E[\\vec x].\\)"
  },
  {
    "objectID": "60-hypothesis-test.html#giả-thuyết",
    "href": "60-hypothesis-test.html#giả-thuyết",
    "title": "6  Kiểm định",
    "section": "6.1 Giả thuyết",
    "text": "6.1 Giả thuyết\nVới mô hình thống kê \\(\\left(E,(\\P_\\theta)_{\\theta\\in\\Theta}\\right),\\) sử dụng bộ mẫu dữ liệu iid \\(X_1,\\ldots,X_n,\\) ta xem xét hai giả thuyết về tham số \\(\\theta\\) như sau:\n\\[\n\\begin{cases}\nH_0:&\\theta\\in\\Theta_0\\\\\nH_1:&\\theta\\in\\Theta_1\n\\end{cases}\n\\]\nvới \\(\\Theta_0,\\Theta_1\\) là phân mảnh (không giao nhau) của \\(\\Theta,\\) \\(\\Theta_0\\) là “thường thức” (status quo), còn \\(\\Theta_1\\) là “phát hiện” (discovery) mới. Ta gọi \\(H_0\\) là giả thuyết không, còn \\(H_1\\) là giả thuyết đối (thay thế).\n\n6.1.1 Kiểm định\nTa sẽ kiểm định \\(H_0\\) đối với \\(H_1\\) bằng cách chọn và sử dụng một định lượng thống kê \\(\\psi(X_1,\\ldots,X_n)\\in\\{0,1\\}.\\)\n\n\n\n\n\n\n\n\n\n\\(\\psi=0:\\) chấp nhận \\(H_0\\)\n\\(\\psi=1:\\) phủ nhận \\(H_0\\)\n\n\n\n\n\\(\\theta\\in\\Theta_0\\)\nKiểm định đúng\nLỗi loại 1\n\n\n\\(\\theta\\in\\Theta_1\\)\nLỗi loại 2\nKiểm định đúng\n\n\n\nCó thể viết \\(\\psi=\\indicator{R_\\psi}\\) với sự kiện \\(R_\\psi\\) là vùng phủ nhận, còn \\(R_\\psi^c\\) là vùng chấp nhận .\nTa thiết kế kiểm định sao cho hàm công suất sau đây có giá trị nhỏ khi \\(\\theta\\in\\Theta_0\\) và lớn khi \\(\\theta\\in\\Theta_1:\\)\n\\[\n\\beta_\\psi(\\theta) \\is \\P_\\theta(\\psi=1) \\equiv \\P_\\theta(R_\\psi)\\in[0,1]\n\\]\nVùng phủ nhận thường có dạng \\[\nR_\\psi = \\{X_i: T(X_i)\\geq c\\}\n\\] với \\(T\\) là một lượng thống kê còn \\(c\\) là một giá trị biên.\n\n\n6.1.2 Mức độ lỗi\nKiểm định \\(\\psi\\) là ở mức (significance level) \\(\\alpha\\in(0,1)\\) nếu có xác suất lỗi loại 1 không vượt quá \\(\\alpha:\\) \\[\n\\sup_{\\theta\\in\\Theta_0}\n\\beta_\\psi(\\theta)\n\\leq\\alpha\n.\n\\]\nChuỗi kiểm định \\((\\psi_n)_{n=1,2,\\ldots}\\) được gọi là tiệm cận về mức \\(\\alpha\\) nếu \\[\n\\lim_{n\\to\\infty}\n\\sup_{\\theta\\in\\Theta_0}\n\\beta_{\\psi_n}(\\theta)\n\\leq\\alpha\n.\n\\]\nPhương thức Neyman-Pearson chọn một mức \\(\\alpha\\), đảm bảo xác suất lỗi loại 1 không vượt quá \\(\\alpha\\) rồi tối thiểu hóa xác suất lỗi loại 2. Nói cách khác là giữ cho công suất \\(\\beta_\\psi(\\theta)\\) đủ nhỏ khi \\(\\psi\\in\\Theta_0,\\) rồi tối đại hóa công suất khi \\(\\psi\\in\\Theta_1.\\)\n\n\n6.1.3 p-value\nTừ quan sát \\(X_1, \\ldots, X_n\\) ta tính giá trị mức \\(\\alpha\\) (tiệm cận) nhỏ nhất tại đó kiểm định \\(\\psi\\) phủ nhận \\(H_0,\\) gọi nó là p-value (tiệm cận) của \\(\\psi.\\) Nếu p-value càng nhỏ thì ta càng tự tin phủ nhận \\(H_0.\\)\n\\[\n\\textrm{p-value} \\is\n\\inf_{X_1, \\ldots, X_n; \\theta\\in H_0}\\beta_\\psi(\\theta)\n\\]\n\n\n\np-value\nchứng cứ phủ nhận \\(H_0\\)\n\n\n\n\n\\(<0.1\\%\\)\nvô cùng mạnh\n\n\n\\(0.1\\%\\textemdash 1\\%\\)\nrất mạnh\n\n\n\\(1\\%\\textemdash 5\\%\\)\nmạnh\n\n\n\\(5\\%\\textemdash 10\\%\\)\nyếu\n\n\n\\(>10\\%\\)\nkhông có\n\n\n\n\n\n6.1.4 Khoảng tin cậy\nThông thường ta có thể xây dựng được kiểm định từ khoảng tin cậy. Ví dụ, ta muốn kiếm định tham số \\(\\theta\\), \\(H_0: \\theta=\\theta_0,\\) đối \\(H_1: \\theta\\neq\\theta_0.\\) Giả sử ta có khoảng tin cậy \\(\\mathcal{I}\\) ở mức \\(1-\\alpha\\), tức là \\[\\P_\\theta(I\\ni \\theta)\\geq 1-\\alpha.\\] Khi đó, \\(\\psi=\\indicator{\\theta_0\\notin\\mathcal{I}}\\) là kiểm định mức \\(\\alpha\\)\n\\[\n\\beta_\\psi(\\theta_0) = \\P_{\\theta_0}(\\theta_0\\notin I) \\leq \\alpha.\n\\]"
  },
  {
    "objectID": "60-hypothesis-test.html#kiểm-định-tham-số",
    "href": "60-hypothesis-test.html#kiểm-định-tham-số",
    "title": "6  Kiểm định",
    "section": "6.2 Kiểm định tham số",
    "text": "6.2 Kiểm định tham số\n\n6.2.1 Wald Test\nGiả sử \\(\\hat{\\theta}\\) là ước lượng của tham số \\(\\theta\\), và \\(\\hat{\\V}[\\hat{\\theta}]\\) là ước lượng phương sai của \\(\\hat{\\theta}\\), sao cho \\[\n\\frac{\\hat{\\theta}-\\theta}\n{\\sqrt{\\hat{\\V}[\\hat{\\theta}]}}\n\\todist\n\\Gaus{0}{1}.\n\\]\nĐặt\n\\[\nW \\is \\frac{\\hat{\\theta}-\\theta_0}\n{\\sqrt{\\hat{\\V}[\\hat{\\theta}]}}\n,\n\\]\nta có thể xây dựng các kiểm định Wald có mức tiệm cận là \\(\\alpha,\\) tức là \\(\\P_{H_0}(\\psi_\\alpha) \\xrightarrow[n\\to\\infty]{} \\alpha.\\)\n\n\n\n\n\n\n\n\nGiả thuyết\nKiểm định Wald\nasymp. p-value\n\n\n\n\n\\(H_0: \\theta=\\theta_0, H_1: \\theta\\neq\\theta_0\\)\n\\(\\psi_\\alpha=\\indicator{|W|>q_{\\alpha/2}}\\)\n\\(\\P(|Z|>|W^{obs}|)\\)\n\n\n\\(H_0: \\theta\\leq\\theta_0, H_1: \\theta>\\theta_0\\)\n\\(\\psi_\\alpha=\\indicator{W>q_\\alpha}\\)\n\\(\\P(Z>W^{obs})\\)\n\n\n\\(H_0: \\theta\\geq\\theta_0, H_1: \\theta<\\theta_0\\)\n\\(\\psi_\\alpha=\\indicator{W<-q_\\alpha}\\)\n\\(\\P(Z<W^{obs})\\)\n\n\n\nTrong bảng trên, p-value được tính từ \\(W^{obs}\\) là một quan sát đối với \\(W.\\)\n\n\n6.2.2 Định lý Cochran\n\nĐịnh lý 6.1 Giả sử \\(X_1,\\ldots,X_n\\iid\\Gaus{\\mu}{\\sigma^2}.\\) Đặt \\[\nS_n^2\\is\\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\bar{X}_n)^2.\n\\]\nKhi đó \\(\\E[S_n^2] \\equiv \\sigma^2,\\) \\[\n\\frac{S_n^2}{\\sigma^2}\n\\sim\n\\frac{\\chi_{n-1}^2}{n-1}\n,\n\\]\nvà \\(\\bar{X}_n, S_n^2\\) độc lập với nhau.\n\n\n\n6.2.3 Student’s T test\nGiả sử \\(X_1,\\ldots,X_n\\iid\\Gaus{\\mu}{\\sigma^2},\\) \\(\\mu,\\sigma\\) chưa biết, và ta muốn kiểm định \\(\\mu.\\) Theo ĐL 6.1, \\[\nT\\is\n\\frac{\\bar{X}_n-\\mu}{\\sqrt{S_n^2/n}}\n\\equiv\n\\frac{\\sqrt{n}{(\\bar{X}_n-\\mu)}{/\\sigma}}\n{\\sqrt{{S_n^2}{/\\sigma^2}}}\n\\sim t_{n-1}\n\\] tuân theo phân phối Student’s T. Ta có thể xây dựng các kiểm định Student có mức \\(\\alpha,\\) tức là \\(\\P_{H_0}(\\psi_\\alpha) \\equiv \\alpha.\\)\n\n\n\n\n\n\n\n\nGiả thuyết\nKiểm định Student\np-value\n\n\n\n\n\\(H_0: \\mu=\\mu_0, H_1: \\mu\\neq\\mu_0\\)\n\\(\\psi_\\alpha=\\indicator{|T| >q_{\\alpha/2}^{t_{n-1}}}\\)\n\\(\\P_{t_{n-1}}(|Z|>|T^{obs}|)\\)\n\n\n\\(H_0: \\mu\\leq\\mu_0, H_1: \\mu>\\mu_0\\)\n\\(\\psi_\\alpha=\\indicator{T>q_\\alpha^{t_{n-1}}}\\)\n\\(\\P_{t_{n-1}}(Z>T^{obs})\\)\n\n\n\\(H_0: \\mu\\geq\\mu_0, H_1: \\mu<\\mu_0\\)\n\\(\\psi_\\alpha=\\indicator{T<-q_\\alpha^{t_{n-1}}}\\)\n\\(\\P_{t_{n-1}}(Z<T^{obs})\\)\n\n\n\nTrong bảng trên, p-value được tính từ \\(T^{obs}\\) là một quan sát đối với \\(T.\\)\n\n\n6.2.4 Two-sample T-test\nGiả sử \\(X_1,\\ldots,X_n\\iid\\Gaus{\\mu_x}{\\sigma_x^2},\\) \\(Y_1,\\ldots,Y_m\\iid\\Gaus{\\mu_y}{\\sigma_y^2},\\) với \\(\\mu_x,\\sigma_x, \\mu_y,\\sigma_y\\) chưa biết, và ta muốn kiểm định \\(\\mu_x-\\mu_y.\\) Đặt \\[ \\hat{\\mu}_n\\is\\frac{1}{n}\\sum_{i=1}^{n}X_i,\\quad\n\\hat{\\sigma}_n^2\\is\\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\hat{\\mu}_n)^2\n,\n\\] \\[ \\hat{\\mu}_m\\is\\frac{1}{m}\\sum_{i=1}^{m}Y_i,\\quad\n\\hat{\\sigma}_m^2\\is\\frac{1}{m-1}\\sum_{i=1}^{m}(Y_i-\\hat{\\mu}_m)^2\n.\\] Ta có gần đúng \\[\n\\frac{(\\hat{\\mu}_n-\\hat{\\mu}_m)-(\\mu_x-\\mu_y)}\n{\\sqrt{\\hat{\\sigma}_n^2/n + \\hat{\\sigma}_m^2/m}}\n\\sim t_N\n\\] là phân phối Student’s T với độ tự do tuân theo công thức WS (Welch-Satterthwaite): \\[\nN =\n\\frac{(\\hat{\\sigma}_n^2/n + \\hat{\\sigma}_m^2/m)^2}\n{{{\\hat{\\sigma}_n^4}/{\\left(n^2(n-1)\\right)}  +\n{\\hat{\\sigma}_m^4}/{\\left(m^2(m-1)\\right)}}}\n\\geq \\min(n, m)\n\\] Đặt \\[\nT = \\frac{\\hat{\\mu}_n-\\hat{\\mu}_m}\n{\\sqrt{\\hat{\\sigma}_n^2/n + \\hat{\\sigma}_m^2/m}}\n.\\]\n\n\n\n\n\n\n\n\nGiả thuyết\nKiểm định 2 mẫu\np-value\n\n\n\n\n\\(H_0: \\mu_x=\\mu_y, H_1: \\mu_x\\neq\\mu_y\\)\n\\(\\psi_\\alpha=\\indicator{|T| >q_{\\alpha/2}^{t_{N}}}\\)\n\\(\\P_{t_{N}}(|Z|>|T^{obs}|)\\)\n\n\n\\(H_0: \\mu_x\\leq\\mu_y, H_1: \\mu_x>\\mu_y\\)\n\\(\\psi_\\alpha=\\indicator{T>q_\\alpha^{t_{N}}}\\)\n\\(\\P_{t_{N}}(Z>T^{obs})\\)\n\n\n\\(H_0: \\mu_x\\geq\\mu_y, H_1: \\mu_x<\\mu_y\\)\n\\(\\psi_\\alpha=\\indicator{T<-q_\\alpha^{t_{N}}}\\)\n\\(\\P_{t_{N}}(Z<T^{obs})\\)\n\n\n\n\n\n6.2.5 Kiểm định tỷ lệ hợp lý\nLikelihood ratio test\nVới dữ liệu \\(X_1,\\ldots,X_n\\iid \\P_\\theta,\\) để kiểm định \\(H_0: \\theta \\in \\Theta_0,\\) \\(H_1: \\theta \\notin \\Theta_0,\\) định lượng tỷ lệ hợp lý là \\[\nT_n =\n2\\ln\\frac{{L_n}(\\hat{\\theta})}{{L_n}(\\hat{\\theta}_0)}\n\\] với \\(L(\\hat{\\theta})\\) là hợp lý cực đại tổng quát, còn \\(L(\\hat{\\theta}_0)\\) là hợp lý cực đại khi \\(H_0\\) đúng.\n\n\n6.2.6 Định lý Wilks\nGiả sử \\(\\theta=\\left(\\theta_1,\\ldots,\\theta_{q+r}\\right) \\in\\Theta\\subset\\R^{q+r},\\) \\[\n\\Theta_0=\\left\\{\\theta\\in\\Theta:\n\\left(\\theta_{q+1},\\ldots,\\theta_{q+r}\\right)\n=\n\\left(\\theta_{q+1}^{(0)},\\ldots,\\theta_{q+r}^{(0)}\\right)\n\\right\\}\n\\] với \\(\\left(\\theta_{q+1}^{(0)},\\ldots,\\theta_r^{(0)}\\right)\\in\\R^r\\) là cố định. Nếu \\(H_0\\) đúng và các điều kiện hội tụ của MLE (ĐL 5.2) được thỏa mãn thì: \\[\nT_n\\todist\\chi_{r}^2.\n\\]\n\n\n6.2.7 Kiểm định nhiều lần\nGọi số lần thực hiện và quan sát kết quả kiểm định là \\(t,\\) mức độ lỗi loại 1 cho phép là \\(\\alpha.\\) Nếu \\(H_0\\) là đúng thì lỗi loại 1 sẽ xuất hiện khoảng \\(\\alpha t\\) lần, số lần này sẽ càng lớn nếu \\(t\\) càng lớn.\nGọi tỷ lệ p-value không vượt quá ngưỡng \\(\\alpha\\) là \\(F(\\alpha)\\is\\P(\\textrm{p-value}\\leq \\alpha).\\) Ta có \\(F(\\alpha)\\leq \\alpha\\) với mọi loại kiểm định. Hơn nữa, \\(F(\\alpha)=\\alpha\\) với kiểm định Student’s T."
  },
  {
    "objectID": "60-hypothesis-test.html#kiểm-định-mô-hình",
    "href": "60-hypothesis-test.html#kiểm-định-mô-hình",
    "title": "6  Kiểm định",
    "section": "6.3 Kiểm định mô hình",
    "text": "6.3 Kiểm định mô hình\n\n6.3.1 Kiểm định \\(\\chi^2\\)\n\nĐịnh lý 6.2 (Kiểm định \\(\\chi^2\\)) Cho mô hình phân loại \\[\n\\left(\n    \\left\\{a_1,\\ldots,a_K\\right\\},\n    \\{\\P_{\\p}\\}_{\\p\\in\\Delta_K}\n\\right)\n,\n\\] với \\(\\Delta_K\\is\\left\\{\\p\\in\\R_+^K: \\sum_{i=1}^K p_i=1\\right\\}.\\) Đặt \\(N_k = \\sum_{i=1}^n \\indicator{X_i=a_k}.\\) Cố định \\(\\p^0\\in\\Delta_K\\), kiểm định \\(H_0: \\p=\\p^0\\) vs \\(H_1: \\p\\neq\\p^0.\\) Nếu \\(H_0\\) là đúng thì \\[\nT_n\\is\nn\\sum_{i=1}^K\\frac{\\left(\\frac{N_i}{n}-p^0_i\\right)^2}{p^0_i}\n\\todist \\chi_{K-1}^2\n.\n\\]\n\n\nĐịnh lý 6.3 (Kiểm định \\(\\chi^2\\) cho hệ phân phối) Xem xét hệ phân phối rời rạc \\(\\P_\\theta\\) có pmf \\(f_\\theta\\) với \\(\\theta\\in\\Theta\\subset\\R^d.\\) Với dữ liệu \\(X_1,\\ldots,X_n\\), gọi MLE của \\(\\theta\\) là \\(\\hat{\\theta},\\) ước lượng \\(\\hat{p}_i\\is f_{\\hat{\\theta}}(a_i),\\,i=1,\\ldots,K.\\) Kiểm định \\(H_0: \\theta\\in\\Theta\\) vs \\(H_1: \\theta\\notin\\Theta.\\) Nếu \\(H_0\\) là đúng thì\n\\[\nT_n\\is\nn\\sum_{i=1}^K\\frac{\\left(\\frac{N_i}{n}-\\hat{p}_i\\right)^2}{\\hat{p}_i}\n\\todist \\chi_{K-d-1}^2\n.\n\\]\n\\(T_n\\) không phải pivotal.\n\n\nHệ quả 6.1 (Kiểm định \\(\\chi^2\\) cho phân phối liên tục) Đối với phân phối liên tục, ta có thể phân hoạch tập giá trị biến thành các khoảng (quantile) để chuyển thành phân phối rời rạc rồi áp dụng kiểm định \\(\\chi^2.\\)\n\n\n\n6.3.2 Kiểm định KS\n\nĐịnh nghĩa 6.1 (Kiểm định Kolmogorov-Smirnov) Gọi \\(F_n\\) là cdf thực nghiệm (ĐN 4.4), \\(F\\) là cdf thật (ĐN 1.3) của \\(X_1,\\ldots,X_n\\iid X.\\) Cho cdf liên tục \\(F^0,\\) kiểm định giả thuyết \\(H_0: F=F^0\\) v.s. \\(H_1: F\\neq F^0.\\) Định lượng kiểm định \\[\nT_n\\is\\sup_{t\\in\\R}\\sqrt{n}\\left|F_n(t)-F^0(t)\\right|\n\\] là pivotal.\n\nTheo định lý Donsker (ĐL 4.2), nếu \\(H_0\\) là đúng thì \\(T_n\\todist Z,\\) với \\(Z\\) là phân bố của đỉnh tuyệt đối của Brownian bridge.\nVì các cdf đều tăng đơn điệu, cdf thực nghiệm có dạng bậc thang, ta có thể xếp \\(X_1\\leq\\ldots\\leq X_n\\) từ nhỏ đến lớn để tính \\(T_n\\) dễ dàng hơn. \\[\nT_n\\equiv\n\\sqrt{n}\n\\max_{i=1,\\ldots,n}\n\\left\\{\n\\max\n\\left\\{\n    \\left|\n        \\frac{i-1}{n} - F^0(X_i)\n    \\right|,\n    \\left|\n        \\frac{i}{n} - F^0(X_i)\n    \\right|\n\\right\\}\n\\right\\}\n.\n\\]\n\n\n6.3.3 Kiểm định KL\n\nĐịnh nghĩa 6.2 (Kolmogorov-Lilliefors test) Trong tiền đề của ĐN 6.1, nếu bỏ điều kiện \\(F_0\\) cố định, thay vào đó là kiểm chứng phân phối \\(\\P\\) thuộc hệ phân phối chuẩn \\(\\{\\Gaus(\\mu,\\sigma^2\\}.\\) Gọi MLE là \\(\\hat{\\mu},\\hat{\\sigma}^2\\), định lượng kiểm định \\[\nT_n\\is\\sup_{t\\in\\R}\\sqrt{n}\\left|F_n(t)-\\Phi_{\\hat{\\mu},\\hat{\\sigma}^2}(t)\\right|\n\\] là pivotal."
  },
  {
    "objectID": "70-bayes-stat.html#phương-pháp",
    "href": "70-bayes-stat.html#phương-pháp",
    "title": "7  Bayesian",
    "section": "7.1 Phương pháp",
    "text": "7.1 Phương pháp\n\nĐịnh nghĩa 7.1 (Bayesian method) Với dữ liệu \\(X_1,\\ldots,X_n,\\) ta ước lượng tham số \\(\\theta\\) cho mô hình xác suất qua các bước:\n\nGán xác suất tiên nghiệm (prior) \\(\\pi(\\theta)\\) cho tham số \\(\\theta\\in\\Theta.\\)\nChọn xác suất \\(f(X|\\theta)\\) phụ thuộc vào \\(\\theta,\\) gọi MLE (ĐN 5.5) là \\(L_n\\)\nTính xác suất hậu nghiệm (posterior) theo Bayes ĐL 1.1:\n\n\\[\n\\begin{split}\n\\pi(\\theta|X_1,\\ldots,X_n)\n&=\n\\frac{\nL_n(X_1,\\ldots,X_n|\\theta)\n\\pi(\\theta)\n}{\n    \\int_{\\theta\\in\\Theta}\nL_n(X_1,\\ldots,X_n|\\theta)\n\\pi(\\theta)\nd\\theta\n}\\\\\n&\\propto\nL_n(X_1,\\ldots,X_n|\\theta)\n\\pi(\\theta),\n\\quad\\theta\\in\\Theta\n.\n\\end{split}\n\\]"
  },
  {
    "objectID": "70-bayes-stat.html#loại-prior",
    "href": "70-bayes-stat.html#loại-prior",
    "title": "7  Bayesian",
    "section": "7.2 Loại prior",
    "text": "7.2 Loại prior\n\nĐịnh nghĩa 7.2 (Conjugate prior) Nếu xác suất tiền nghiệm và xác suất hậu nghiệm thuộc cùng một hệ xác suất, ta nói xác suất tiền nghiệm là liên hợp đối với mô hình.\n\n\nVí dụ 7.1 Beta là xác suất liên hợp tiền nghiệm đối với mô hình Bernoulli \\(\\Ber\\), nhị thức \\(\\Bin\\) và hình học \\(\\Geom.\\)\n\n\nĐịnh nghĩa 7.3 (Non informative prior) Nếu ta không có thông tin tiền nghiệm gì về tham số \\(\\theta\\in\\Theta=[a, b]\\) thì có thể dùng phân phối đồng đều \\(\\Unif[a,b]\\) làm xác suất tiền nghiệm.\n\n\nĐịnh nghĩa 7.4 (Improper prior) Nếu hàm \\(\\pi:\\Theta\\to[0,+\\infty)\\) là đo được (measurable) nhưng không khả tích toàn phần trên \\(\\Theta\\) thì ta nói \\(\\pi\\) là improper prior.\n\n\nĐịnh nghĩa 7.5 (Jeffreys prior) \\[\\pi_J(\\theta)\\propto\\sqrt{\\det I(\\theta)}\n\\] với \\(I(\\theta)\\) là thông tin Fisher (ĐN 5.8) của mô hình thống kê cho \\(X_1,\\ldots,X_n.\\)\n\n\nVí dụ 7.2  \n\nThí nghiệm \\(\\Ber(p), p\\in(0,1)\\) có \\[\\pi_J(p)\\propto\\frac{1}{\\sqrt{p(1-p)}}\\propto\\Beta{\\frac{1}{2}}{\\frac{1}{2}}\n.\\]\nThí nghiệm \\(\\Gaus{\\mu}{1}, \\mu\\in\\R\\) có \\(\\pi_J(\\mu)\\propto 1\\) là improper prior."
  },
  {
    "objectID": "references.html#giáo-trình",
    "href": "references.html#giáo-trình",
    "title": "Tham khảo",
    "section": "Giáo trình",
    "text": "Giáo trình\n\n\nJohn Tsitsiklis, Dimitri Bertsekas, Partick Jaillet. 2022.\n“Probability - the Science of Uncertainty and Data.” MITx.\nhttps://www.edx.org/course/probability-the-science-of-uncertainty-and-data.\n\n\nPhilippe Rigollet, Tyler Maunu, Jan Christian Huetter. 2022.\n“Fundamentals of Statistics.” MITx. https://www.edx.org/course/fundamentals-of-statistics.\n\n\nWasserman, Larry. 2004. All of Statistics : A Concise Course in\nStatistical Inference. New York: Springer. https://archive.org/details/springer_10.1007-978-0-387-21736-9."
  },
  {
    "objectID": "references.html#mitx-18.6501x",
    "href": "references.html#mitx-18.6501x",
    "title": "Tham khảo",
    "section": "MITx 18.6501x",
    "text": "MITx 18.6501x\n“Fundamentals of Statistics” (MITx 18.6501x ) là khóa học của Philippe Rigollet (2022) đại học MIT dạy trên edX.\n\nQuy định\n\nKỳ hạn\n\nExercises and homework: Wednesdays 11:59AM UTC (Wed. 20:59 JST)\nExams (48 hours): Tuesdays 11:59AM UTC(Tue. 20:59 JST)\n\n\n\nThời gian cần thiết\nMỗi tuần khoảng hơn 12 tiếng\n\n5-7 hours on exercises, including 3 hours of lecture clips\n1-2 hours watching recitations\n5-7 hours for weekly problem sets\n\n\n\nTính điểm\nĐiểm thi đậu chứng chỉ là 60% tổng số điểm tối đa.\n\n20% for the lecture exercises (divided equally among the 20 out of 23 lectures)\n20% for the homeworks (divided equally among 10 (out of 12) homeworks)\n18% for the first midterm exam (timed)\n18% for the second midterm exam (timed)\n24% for the final exam (timed)\n\n\n\n\nUnit 1\nÔn lại kiến thức về xác suất “Probability - The Science of Uncertainty and Data” by John Tsitsiklis (2022).\n\n\nUnit 2\nHọc về nền tảng của suy luận (Foundations of Inference).\n\nLecture 3: Mô hình xác suất có số biến hữu hạn (Parametric Statistical Models)\nLecture 4: Dự đoán với số biến hữu hạn và vùng tự tin (Parametric Estimation and Confidence Intervals) \\({}\\)\nLecture 5: Vùng tự tin và phương pháp Delta (Confidence Intervals and Delta Method)\n\n\n\nUnit 3\nPhương pháp ước lượng tham số của mô hình xác suất\n\nLecture 6: Khoảng cách giữa các phân phối xác suất\nLecture 7: Maximum Likelihood Estimator\nLecture 8: Ví dụ cho Maximum Likelihood Estimator\nLecture 9: Các tính chất thống kê của Maximum Likelihood Estimator\nLecture 10: Phương pháp tích suất và M-Estimation\n\n\n\nUnit 4\nKiểm định thống kê\n\nLecture 11: Introduction to Parametric Hypothesis Testing\nLecture 12: The Wald Test and Likelihood Ratio Test\nLecture 13: The T-test\nLecture 14: Multiple Hypothesis Testing"
  }
]