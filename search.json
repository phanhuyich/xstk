[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "XSTK",
    "section": "",
    "text": "$$\n\\def\\argmax{\\operatorname*{argmax}}\n\\def\\argmin{\\operatorname*{argmin}}\n\\def\\as{\\textrm{a.s.}}\n\\def\\Ber{\\text{Ber}}\n\\def\\Bin{\\text{Bin}}\n\\def\\Unif{\\text{Unif}}\n\\def\\E{\\mathbb{E}}\n\\def\\iid{\\stackrel{iid}{\\sim}}\n\\def\\is{:=}\n\\def\\Gaus{\\mathcal{N}}\n\\def\\P{\\mathbb{P}}\n\\def\\Poi{\\text{Poi}}\n\\def\\R{\\mathbb{R}}\n\\def\\V{\\mathbb{V}}\n\\def\\N{\\mathbb{Z}_+}\n\\def\\TV{\\textrm{TV}}\n\\def\\KL{\\textrm{KL}}\n\\def\\vec#1{\\boldsymbol{#1}}\n$$"
  },
  {
    "objectID": "10-proba-intro.html",
    "href": "10-proba-intro.html",
    "title": "1  Xác suất",
    "section": "",
    "text": "Không gian \\(\\Omega\\) là tập hợp chứa tất cả những hiện tượng \\(\\omega\\) có thể xảy ra từ một thí nghiệm. Các tập con của \\(\\Omega\\) là các sự kiện.\nVí dụ xem xét thí nghiệm tung một đồng xu đúng hai lần, quan sát đồng xu rớt xuống nằm ngửa (\\(H\\)) hay sấp (\\(T\\)), ta có \\(\\Omega = \\{HH, HT, TH, TT\\}\\) bao gồm 4 kết quả có thể xảy ra. Sự kiện lần tung đầu tiên ra mặt ngửa của đồng xu là tập hợp \\(\\{HH, HT\\}.\\)\nCho một sự kiện \\(A\\subseteq\\Omega\\), ta nói \\(A\\) xảy ra, hoặc \\(A\\) là đúng, nếu có một hiện tượng \\(\\omega\\in A\\) xảy ra. Sự kiện ngược lại với \\(A\\) là \\(A^c\\is\\Omega-A\\is \\{\\omega\\in\\Omega: \\omega\\notin A\\}\\), tức là “không xảy ra \\(A\\)”. Theo định nghĩa, rõ ràng \\(\\Omega\\) luôn luôn đúng, còn sự kiện rỗng \\(\\emptyset\\equiv\\Omega^c\\) luôn luôn sai. Cho thêm sự kiện \\(B\\), ta có \\(A\\cup B\\) là sự kiện “\\(A\\) hoặc \\(B\\) ít nhất một việc xảy ra”, còn \\(AB\\is A\\cap B\\) là sự kiện “\\(A\\) và \\(B\\) đồng thời xảy ra”.\nChuỗi sự kiện \\(A_1, A_2, \\ldots\\) được gọi là phân ly nếu \\(A_i A_j\\equiv\\emptyset\\) với mọi \\(i\\neq j\\). Khi đó nếu \\(A_1\\cup A_2\\cup\\cdots\\equiv C\\) thì ta nói \\(A_1, A_2, \\ldots\\) là một cách phân hoạch sự kiện \\(C\\)."
  },
  {
    "objectID": "10-proba-intro.html#xác-suất",
    "href": "10-proba-intro.html#xác-suất",
    "title": "1  Xác suất",
    "section": "1.2 Xác suất",
    "text": "1.2 Xác suất\nNếu một xạ ảnh \\(\\P\\) từ không gian các sự kiện \\(A\\subseteq\\Omega\\) lên tập hợp số thực \\(\\R\\) thỏa mãn các điều kiện:\n\n\\(\\P(A)\\geq 0\\quad\\forall A\\)\n\\(\\P(\\Omega) = 1\\)\nNếu chuỗi \\(A_1, A_2, \\ldots\\) phân hoạch \\(C\\) thì \\(\\P(A_1) + \\P(A_2) + \\cdots = \\P(C)\\)\n\nthì ta gọi \\(\\P\\) là một phân phối xác suất hoặc độ đo xác suất.\nCó hai cách cắt nghĩa khái niệm xác suất là tần suất và niềm tin. Theo cách hiểu tần suất thì \\(\\P(A)\\) chính là tỷ lệ số lần sự kiện \\(A\\) xảy ra nếu ta thực hiện thí nghiệm vô số lần. Còn theo cách hiểu niềm tin thì \\(\\P(A)\\) là thước đo mức độ mà một quan sát viên tin tưởng rằng hiện tượng \\(A\\) sẽ xảy ra.\n\n1.2.1 Biến ngẫu nhiên\n\nDef 1.1 (“random variable”, rv) là một quy tắc ánh xạ \\(X: \\Omega\\to\\R\\) gán cho mỗi hiện tượng \\(\\omega\\) trong không gian \\(\\Omega\\) một số thực \\(X(\\omega).\\)\n\n\n\n1.2.2 Điểm cắt\n\nDef 1.2 Điểm cắt tại mức \\(1-\\alpha\\) của biến \\(X\\) là một số \\(q_\\alpha\\) mà \\(\\P(X\\leq q_\\alpha)=1-\\alpha.\\)\n\n\n\n1.2.3 Độc lập\n\nDef 1.3 Hai sự kiện \\(A\\) và \\(B\\) là độc lập nếu \\(\\P(AB)\\equiv \\P(A)\\P(B)\\).\nHai biến \\(X\\) và \\(Y\\) là độc lập nếu hai sự kiện \\(X\\leq x\\) và \\(Y\\leq y\\) là độc lập đối với mọi \\(x,y\\).\n\n\n\n1.2.4 IID\n\nDef 1.4 Các biến ngẫu nhiên \\(X_1, X_2, \\ldotp\\) được gọi là iid (“independent and identically distributed”, “độc lập và phân phối giống nhau”) nếu chúng cùng tuân theo duy nhất một phân phối xác suất, và từng cặp biến là độc lập với nhau. Dùng biến \\(X\\) để thể hiện phân phối xác suất chung đó, ta viết \\[X_1,\\ldots,X_n \\iid X.\\]\n\n\n\n1.2.5 Xác suất hợp\n\nDef 1.5 Ký hiệu \\(\\P(A, B)\\) hoặc \\(\\P(A\\cap B)\\) chỉ xác suất sự kiện \\(A\\) và sự kiện \\(B\\) đồng thời xảy ra.\n\n\n\n1.2.6 Xác suất có điều kiện\n\nDef 1.6 Ký hiệu \\(\\P(A|B)\\) hoặc \\(\\P_B(A)\\) chỉ xác suất của sự kiện \\(A\\), khi biết sự kiện \\(B\\) đã xảy ra,\n\\[\\P(A|B) = \\frac{\\P(A,B)}{\\P(B)}.\\]\n\n\n\n1.2.7 Định lý Baye\n\nThm 1.1 \\[\\P(A|B) = \\frac{\\P(B|A)\\P(A)}{\\P(B)}\n= \\frac{\\P(B|A)\\P(A)}{\\P(B|A)\\P(A) + \\P(B|A^c)\\P(A^c)}\n.\\]"
  },
  {
    "objectID": "10-proba-intro.html#trung-bình",
    "href": "10-proba-intro.html#trung-bình",
    "title": "1  Xác suất",
    "section": "1.3 Trung bình",
    "text": "1.3 Trung bình\n\nDef 1.7 Trung bình, hay giá trị kỳ vọng của biến X là\n\\[\n\\E[X]\\is\n\\int x dF(x)\n\\is\n\\begin{cases}\n\\sum_x x p(x) & \\textrm{ if } X \\textrm{ is discrete}\\\\\n\\int x f(x) dx & \\textrm{ if } X \\textrm{ is continuous}.\n\\end{cases}\n\\]\n\nNếu giá trị \\(\\int |x| dF(x) < \\infty\\) ta nói là \\(\\E[X]\\) “tồn tại” (well-defined).\nTa có \\[\n\\E[X+Y] \\equiv \\E[X] + E[Y].\n\\]"
  },
  {
    "objectID": "10-proba-intro.html#hiệp-phương-sai",
    "href": "10-proba-intro.html#hiệp-phương-sai",
    "title": "1  Xác suất",
    "section": "1.4 Hiệp phương sai",
    "text": "1.4 Hiệp phương sai\n\nDef 1.8 \\[\\begin{align}\n\\textrm{Cov}[X,Y] &\\is \\E[(X-\\E[X])(Y-\\E[Y])] \\\\\n&\\equiv \\E[XY] - \\E[X]\\E[Y]\n\\end{align}\\]\n\nNếu \\(X\\) và \\(Y\\) độc lập thì \\(\\textrm{Cov}[X,Y] = 0\\)."
  },
  {
    "objectID": "10-proba-intro.html#phương-sai",
    "href": "10-proba-intro.html#phương-sai",
    "title": "1  Xác suất",
    "section": "1.5 Phương sai",
    "text": "1.5 Phương sai\n\nDef 1.9 Phương sai, hay phân tán (variance, 分散) là \\[\n\\V[X]\\is\\textrm{Cov}[X,X]\\equiv\\E[X^2]-\\E^2[X].\n\\]\n\nTa có \\[\n\\V[X+Y] \\equiv \\V[X]+\\V[Y] + 2\\textrm{Cov}[X,Y].\n\\]"
  },
  {
    "objectID": "10-proba-intro.html#tích-suất",
    "href": "10-proba-intro.html#tích-suất",
    "title": "1  Xác suất",
    "section": "1.6 Tích suất",
    "text": "1.6 Tích suất\nTích suất (moment, 積率) thể hiện trọng tâm, độ phân tán, hay độ lệch của phân phối. Tích suất bậc \\(n\\) của biến \\(X\\) với mật độ \\(f(x)\\) là:\n\\[\n\\E[X^n]\\is \\int x^n f(x) dx\n\\]\n\n1.6.1 Hàm tạo tích suất\n\nDef 1.10 “Moment generation function (MGF)” của biến \\(X\\) là \\[\\psi_X(t)\\is\\E[e^{tX}], t\\in\\R.\\]\n\nNếu MGF “tồn tại” xung quanh \\(0\\) thì đạo hàm cấp \\(k\\) của \\(\\psi\\) tại \\(0\\) chính là: \\[\n\\psi_X^{(k)}(0)\\equiv \\E[X^k].\n\\]"
  },
  {
    "objectID": "13-distributions.html",
    "href": "13-distributions.html",
    "title": "2  Phân phối",
    "section": "",
    "text": "Có một số phân phối xác suất thông dụng."
  },
  {
    "objectID": "13-distributions.html#phân-phối-bernoulli",
    "href": "13-distributions.html#phân-phối-bernoulli",
    "title": "2  Phân phối",
    "section": "2.1 Phân phối Bernoulli",
    "text": "2.1 Phân phối Bernoulli\n\nDef 2.1 \\(X\\sim\\Ber(p)\\) có \\[\n\\P(X=1) = p = 1-\\P(X=0)\n\\] và \\(\\E[X] = p, \\V[X] = p(1-p)\\)."
  },
  {
    "objectID": "13-distributions.html#phân-phối-binomial",
    "href": "13-distributions.html#phân-phối-binomial",
    "title": "2  Phân phối",
    "section": "2.2 Phân phối Binomial",
    "text": "2.2 Phân phối Binomial\n\nDef 2.2 \\(X\\sim\\Bin(n, p)\\) với \\(n\\in\\N, p\\in(0,1)\\) mô tả tổng số lần thành công của \\(n\\) thí nghiệm độc lập \\(X_1,\\ldots,X_n \\iid \\Ber(p).\\) Ta có \\[\n\\P(X=k) = \\binom{n}{k}p^{k}(1-p)^{n-k}\n\\] và \\(\\E[X] = np, \\V[X] = np(1-p)\\)."
  },
  {
    "objectID": "13-distributions.html#phân-phối-poisson",
    "href": "13-distributions.html#phân-phối-poisson",
    "title": "2  Phân phối",
    "section": "2.3 Phân phối Poisson",
    "text": "2.3 Phân phối Poisson\n\nDef 2.3 \\(X\\sim\\Poi(\\lambda)\\) thường dùng để mô tả số lần \\(k\\) mà sự kiện phát sinh trong một giới hạn cố định, với giả định tần suất phát sinh sự kiện là \\(\\lambda > 0\\) cố định, và các sự kiện phát sinh độc lập. \\[\n\\P(X=k) = e^{-\\lambda}\n\\frac{\\lambda^k}{k!}, \\,k=0,1,2,\\ldots\n\\] và \\(\\E[X] = \\V[X] = \\lambda\\).\n\nKhi \\(n\\) đủ lớn và \\(p\\) đủ nhỏ thì \\(\\Poi(np)\\) gần với \\(\\Bin(n,p)\\)."
  },
  {
    "objectID": "13-distributions.html#phân-phối-geometric",
    "href": "13-distributions.html#phân-phối-geometric",
    "title": "2  Phân phối",
    "section": "2.4 Phân phối Geometric",
    "text": "2.4 Phân phối Geometric\n\nDef 2.4 \\(X\\sim\\text{Geom}(p), p \\in (0,1)\\) có \\[\n\\P(X=k)=p(1-p)^{k-1}, k=1,2,\\ldots\n\\] và \\(\\E[X]=1/p,\\V[X]=(1-p)/p^2.\\)"
  },
  {
    "objectID": "13-distributions.html#phân-phối-exponential",
    "href": "13-distributions.html#phân-phối-exponential",
    "title": "2  Phân phối",
    "section": "2.5 Phân phối Exponential",
    "text": "2.5 Phân phối Exponential\n\nDef 2.5 \\(X\\sim\\text{Exp}(\\lambda)\\) dùng để mô tả khoảng cách \\(x\\) giữa hai lần phát sinh của một chuỗi sự kiện kiểu Poisson (hai lần phát sinh sự kiện liên tiếp là độc lập với nhau, và tần suất phát sinh \\(\\lambda>0\\) là cố định). Có \\[\nf(x)={\\lambda}e^{-\\lambda x},x\\in\\R_+\n\\] và \\(\\E[X]=1/\\lambda,\\V[X]=1/\\lambda^2.\\)"
  },
  {
    "objectID": "13-distributions.html#phân-phối-gaussian",
    "href": "13-distributions.html#phân-phối-gaussian",
    "title": "2  Phân phối",
    "section": "2.6 Phân phối Gaussian",
    "text": "2.6 Phân phối Gaussian\n\nDef 2.6 \\(X\\sim\\Gaus(\\mu,\\sigma^2)\\) có mật độ \\[\nf(x) =\n\\frac{1}{\\sqrt{\\pi 2\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\nx\\in\\R\n\\] và \\(\\E[X]=\\mu,\\V[X]=\\sigma^2\\).\n\n\nThm 2.1 Nếu \\(X_i \\sim\\Gaus(\\mu_i,\\sigma_i^2) (i=1,\\ldots,n)\\) thì\n\\[\\sum_{i=1}^n X_i\\sim\\Gaus\\left(\\sum_{i=1}^n \\mu_i,\\sum_{i=1}^n \\sigma_i^2\\right)\\]"
  },
  {
    "objectID": "15-proba-converge.html",
    "href": "15-proba-converge.html",
    "title": "3  Hội tụ",
    "section": "",
    "text": "Có một số kiểu hội tụ của biến ngẫu nhiên."
  },
  {
    "objectID": "15-proba-converge.html#hội-tụ-xác-suất",
    "href": "15-proba-converge.html#hội-tụ-xác-suất",
    "title": "3  Hội tụ",
    "section": "3.1 Hội tụ xác suất",
    "text": "3.1 Hội tụ xác suất\n\nDef 3.1 Cho một chuỗi biến ngẫu nhiên \\(X_1,X_2,\\ldotp\\) và một biến ngẫu nhiên \\(X\\).\n\nHội tụ gần tuyệt đối: \\[\nX_n \\xrightarrow[n\\to\\infty]{\\as} X \\iff\n\\P(\\{\\omega\\in\\Omega: X_n(\\omega)\\to X(\\omega)\\}) = 1.\n\\]\nHội tụ theo xác suất: \\[\nX_n \\xrightarrow[n\\to\\infty]{\\P} X \\iff\n\\P(|X_n-X| >\\epsilon)\n\\xrightarrow[n\\to\\infty]{}\n0,\\quad\\forall\\epsilon>0.\n\\]\nHội tụ theo phân phối: \\[\nX_n \\xrightarrow[n\\to\\infty]{(d)} X \\iff\n\\P[X_n(x)\\leq x]\\xrightarrow[n\\to\\infty]{} \\P[X\\leq x]\n\\] tại mọi điểm \\(x\\) mà cdf của \\(X\\) liên tục.\nHội tụ về chuẩn: (asymptotically normal) với phương sai \\(\\sigma^2\\) \\[\n\\sqrt{n}({X}_n-X)\\xrightarrow[n\\to\\infty]{(d)}\n\\Gaus(0,\\sigma^2).\n\\]"
  },
  {
    "objectID": "15-proba-converge.html#độ-mạnh",
    "href": "15-proba-converge.html#độ-mạnh",
    "title": "3  Hội tụ",
    "section": "3.2 Độ mạnh",
    "text": "3.2 Độ mạnh\n\nThm 3.1 Xếp theo thứ tự từ mạnh đến yếu:\n\\[\nX_n \\xrightarrow[n\\to\\infty]{\\as} X \\implies\nX_n \\xrightarrow[n\\to\\infty]{\\P} X \\implies\nX_n \\xrightarrow[n\\to\\infty]{(d)} X.\n\\]\nNếu \\(X_n \\xrightarrow[n\\to\\infty]{(d)} X\\), và \\(X\\) có mật độ xác suất, thì \\(X_n \\xrightarrow[n\\to\\infty]{\\P} X\\).\nNếu chuỗi \\(X_n\\) có \\(\\E[X_n]\\xrightarrow[]{} \\mu\\) và \\(\\V[X_n]\\xrightarrow[]{} 0\\) thì \\(X_n\\xrightarrow[]{\\P} \\mu\\).\nNếu \\(X_n\\xrightarrow[n\\to\\infty]{\\P} X\\) thì \\(\\P(a\\leq X_n\\leq b) \\xrightarrow[n\\to\\infty]{} \\P(a\\leq X\\leq b)\\) với mọi khoảng \\([a,b]\\)."
  },
  {
    "objectID": "15-proba-converge.html#tổng-và-tích",
    "href": "15-proba-converge.html#tổng-và-tích",
    "title": "3  Hội tụ",
    "section": "3.3 Tổng và tích",
    "text": "3.3 Tổng và tích\n\nThm 3.2 Nếu có hai chuỗi biến ngẫu nhiên \\(X_n, Y_n\\) hội tụ gần tuyệt đối hoặc hội tụ theo xác suất về \\(X, Y\\), thì tổng \\(X_n+Y_n\\) và tích \\(X_n Y_n\\) cũng hội tụ tương tự (gần tuyệt đối, hoặc theo xác suất) về tổng \\(X+Y\\) và tích \\(XY\\)."
  },
  {
    "objectID": "15-proba-converge.html#slutsky",
    "href": "15-proba-converge.html#slutsky",
    "title": "3  Hội tụ",
    "section": "3.4 Slutsky",
    "text": "3.4 Slutsky\n\nThm 3.3 Nếu \\(Y_n \\xrightarrow[]{\\P} y\\), \\(y\\) là một số thực cố định thì có thể nới lỏng điều kiện đối với \\(X_n\\) thành hội tụ theo phân phối."
  },
  {
    "objectID": "15-proba-converge.html#ánh-xạ-liên-tục",
    "href": "15-proba-converge.html#ánh-xạ-liên-tục",
    "title": "3  Hội tụ",
    "section": "3.5 Ánh xạ liên tục",
    "text": "3.5 Ánh xạ liên tục\n\nThm 3.4 (Continuous mapping) Nếu \\(X_n\\xrightarrow[n\\to\\infty]{\\as/\\P/(d)} X\\) thì đối với mọi hàm \\(f\\) liên tục:\n\n\\(f(X_n)\\xrightarrow[n\\to\\infty]{\\as/\\P/(d)} f(X)\\).\n\\(\\E[f(X_n)]\\xrightarrow[n\\to\\infty]{}\\E[f(X)]\\) nếu \\(f\\) còn bị chặn."
  },
  {
    "objectID": "15-proba-converge.html#đại-đa-số-law-of-large-numbers",
    "href": "15-proba-converge.html#đại-đa-số-law-of-large-numbers",
    "title": "3  Hội tụ",
    "section": "3.6 Đại đa số (Law of Large Numbers)",
    "text": "3.6 Đại đa số (Law of Large Numbers)\n\nThm 3.5 Cho \\(n\\) biến iid \\(X_1, X_2,\\ldotp,X_n\\) có chung \\(\\E[X_i]=\\mu<\\infty\\). Khi đó: \\[\\bar{X}_n\\is\\frac{1}{n}\\sum_{i=1}^n{X_i}\n\\xrightarrow[n\\to\\infty]{\\P,\\,\\as}\\mu.\n\\]"
  },
  {
    "objectID": "15-proba-converge.html#hội-tụ-trung-tâm-central-limit",
    "href": "15-proba-converge.html#hội-tụ-trung-tâm-central-limit",
    "title": "3  Hội tụ",
    "section": "3.7 Hội tụ trung tâm (Central Limit)",
    "text": "3.7 Hội tụ trung tâm (Central Limit)\n\nThm 3.6 Giả sử thêm là \\(\\V[X_i]=\\sigma^2<\\infty\\). Khi đó \\[\n\\sqrt{n}(\\bar{X}_n-\\mu)\n\\xrightarrow[n\\to\\infty]{(d)}\n\\Gaus(0,\\sigma^2).\n\\]"
  },
  {
    "objectID": "15-proba-converge.html#bất-đẳng-thức-hoefding",
    "href": "15-proba-converge.html#bất-đẳng-thức-hoefding",
    "title": "3  Hội tụ",
    "section": "3.8 Bất đẳng thức Hoefding",
    "text": "3.8 Bất đẳng thức Hoefding\n\nThm 3.7 Nếu có một khoảng cố định \\([a,b]\\) gần như tuyệt đối (almost surely) chứa các biến \\(X_i (i=1,2,\\ldots,n)\\) thì\n\\[\n\\P[|\\bar{X}_n-\\mu|\\geq\\epsilon]\\leq\n2e^{-\\frac{2n\\epsilon^2}{(b-a)^2}},\\quad\\forall\\epsilon>0.\n\\]"
  },
  {
    "objectID": "15-proba-converge.html#phương-pháp-delta",
    "href": "15-proba-converge.html#phương-pháp-delta",
    "title": "3  Hội tụ",
    "section": "3.9 Phương pháp Delta",
    "text": "3.9 Phương pháp Delta\n\nThm 3.8 Giả sử chuỗi \\((\\theta_n)_{n\\geq 1}\\) chuẩn tiến với phương sai \\(\\sigma^2\\) về một điểm \\(\\theta\\in\\R\\). Giả sử \\(g:\\R\\to\\R\\) có vi phân \\(g^\\prime\\) liên tục tại \\(\\theta\\). Khi đó, \\[\n\\sqrt{n}(g(\\theta_n)-g(\\theta))\n\\xrightarrow[n\\to\\infty]{(d)}\n\\Gaus\\left(0,\\left(\\sigma g^\\prime(\\theta)\\right)^2\\right)\n\\]"
  },
  {
    "objectID": "20-stat-intro.html",
    "href": "20-stat-intro.html",
    "title": "4  Thống kê",
    "section": "",
    "text": "Trên không gian đo được \\(E\\subseteq\\R\\) ta quan sát các mẫu \\(X_1,\\ldots,X_n\\iid\\P\\). Với tập tham số \\(\\Theta\\) ta xây dựng bộ độ đo xác suất \\((\\P_\\theta)_{\\theta\\in\\Theta}\\) để mô phỏng \\(\\P\\) .\nNếu tồn tại \\(\\theta\\in\\Theta\\) để \\(\\P_\\theta\\equiv\\P\\) thì ta nói mô hình “hợp lệ” (well specified).\nNếu từ tập \\(\\Theta\\), ánh xạ \\(\\theta\\mapsto\\P_{\\theta}\\) là đơn ánh thì ta nói \\(\\theta\\) (hoặc \\(\\P_\\theta\\)) là “có thể xác định” (identifiable).\nNếu \\(\\Theta\\subseteq\\R^d\\) thì mô hình được nói có số biến hữu hạn (parametric model)."
  },
  {
    "objectID": "20-stat-intro.html#ước-lượng",
    "href": "20-stat-intro.html#ước-lượng",
    "title": "4  Thống kê",
    "section": "4.2 Ước lượng",
    "text": "4.2 Ước lượng\nThống kê lượng (statistic) \\(\\theta\\) là bất cứ hàm số nào có thể đo được (measurable function) trên tập dữ liệu đối tượng \\(X_i\\).\nĐánh giá (estimator) \\(\\theta_n\\) đối với mục tiêu thống kê \\(\\theta\\) là một thống kê khác không phụ thuộc vào \\(\\theta\\).\nĐánh giá được gọi là nhất quán (consistent) nếu nó hội tụ về mục tiêu (Def 3.1).\nĐộ lệch (bias) giữa đánh giá \\(\\theta_n\\) với mục tiêu \\(\\theta\\) là \\[\\textrm{bias}_{\\theta}({\\theta}_n) \\is \\E[\\theta_n] - \\theta.\\]\nSai số bậc 2 (quadratic risk, mean squared error) giữa đánh giá \\(\\theta_n\\) với mục tiêu \\(\\theta\\) là \\[\n\\textrm{MSE}(\\theta_n)\\is\\E[(\\theta_n-\\theta)^2]\n\\equiv\n\\textrm{bias}_{\\theta}(\\theta_n)^2\n+\n\\V[\\theta_n]\n\\] bao hàm cả độ lệch và độ nhiễu của đánh giá."
  },
  {
    "objectID": "20-stat-intro.html#khoảng-tin-cậy",
    "href": "20-stat-intro.html#khoảng-tin-cậy",
    "title": "4  Thống kê",
    "section": "4.3 Khoảng tin cậy",
    "text": "4.3 Khoảng tin cậy\nVới mô hình thống kê \\((E,(\\P_\\theta)_{\\theta\\in\\Theta})\\) xây dựng dựa trên quan sát \\(X_1,\\ldots,X_n\\), giả sử số \\(\\alpha\\in(0,1).\\) Khoảng tin cậy (confidence interval) cấp \\(1-\\alpha\\) đối với \\(\\theta\\) là một khoảng ngẫu nhiên \\(\\mathcal{I}\\) (phụ thuộc vào \\(X_1,\\ldots,X_n\\), không phụ thuộc vào \\(\\theta\\)), mà xác suất \\(\\mathcal{I}\\) có chứa \\(\\theta\\) là đủ cao: \\[\\P_\\theta[\\mathcal{I}\\ni\\theta]\\geq 1-\\alpha,\\quad\\forall\\theta\\in\\Theta.\\]\nNếu \\[\\lim_{n\\to\\infty}\\P_\\theta[\\mathcal{I}\\ni\\theta]\\geq 1-\\alpha,\\quad\\forall\\theta\\in\\Theta\\] thì ta gọi \\(\\mathcal{I}\\) là khoảng tin cậy tiệm cận cấp \\(1-\\alpha\\) đối với \\(\\theta\\)."
  },
  {
    "objectID": "30-est-method.html",
    "href": "30-est-method.html",
    "title": "5  Ước lượng",
    "section": "",
    "text": "Chiến lược ước lượng phân phối thật (true distribution)\nVới mô hình thống kê \\((E,(\\P_\\theta)_{\\theta\\in\\Theta})\\) xây dựng dựa trên quan sát iid rv \\(X_1,\\ldots,X_n\\) trên tập mẫu \\(E\\) và bộ tham số \\(\\Theta\\) . Ngầm định tồn tại tham số thật \\(\\theta^*\\in\\Theta\\) để \\(X_1\\sim\\P_{\\theta^*}\\) ."
  },
  {
    "objectID": "30-est-method.html#tổng-biến-động",
    "href": "30-est-method.html#tổng-biến-động",
    "title": "5  Ước lượng",
    "section": "5.1 Tổng biến động",
    "text": "5.1 Tổng biến động\n\n5.1.1 Khoảng cách\n\nDef 5.1 tổng biến động (total variation distance) giữa hai độ đo xác suất \\(\\P_\\theta\\) và \\(\\P_\\eta\\) là\n\\[\n\\TV(\\P_\\theta,\\P_{\\eta})\n=\n\\max_{A\\subset E}{\\mid\\P_\\theta(A)-\\P_\\eta(A)\\mid}.\n\\]\n\n\nThm 5.1 (Công thức tính) Nếu tập mẫu \\(E\\) là rời rạc (discrete: countable or finite), xác suất \\(\\P_\\theta,\\P_{\\eta}\\) có hàm khối lần lượt là \\(p_\\theta,p_{\\eta}\\) thì \\[\n\\TV(\\P_\\theta,\\P_{\\eta}) =\n\\frac{1}{2}\n\\sum_{x\\in E}\\mid p_\\theta(x) - p_\\eta(x)\\mid.\n\\]\nNếu tập mẫu \\(E\\) là liên tục (continuous), xác suất \\(\\P_\\theta, \\P_{\\eta}\\) có mật độ lần lượt là \\(f_\\theta, f_{\\eta}\\) thì \\[\n\\TV(\\P_\\theta,\\P_{\\eta}) =\n\\frac{1}{2}\n\\int_{E}\\mid f_\\theta(x) - f_\\eta(x)\\mid dx.\n\\]"
  },
  {
    "objectID": "30-est-method.html#phân-kỳ-kl",
    "href": "30-est-method.html#phân-kỳ-kl",
    "title": "5  Ước lượng",
    "section": "5.2 Phân kỳ KL",
    "text": "5.2 Phân kỳ KL\n\n5.2.1 Phân kỳ KL\n\nDef 5.2 (KL divergence) Ký hiệu \\(f\\) là mật độ hoặc hàm khối xác suất:\n\\[\n\\KL(\\P_\\theta, \\P_\\eta) \\is\n\\E_\\theta\\left[ \\ln\\frac{f_\\theta(x)}{f_\\eta(x)} \\right]\n=\n\\E_\\theta\\left[ \\ln{f_\\theta(x)} \\right]\n-\n\\E_\\theta\\left[ \\ln{f_\\eta(x)} \\right]\n.\n\\]\n\n\n\n5.2.2 Đặc điểm\n\nProposition 5.1 Phân kỳ KL thỏa mãn 2/4 đặc điểm của “khoảng cách”:\n\n\\(\\KL(\\P_\\theta, \\P_\\eta) \\geq 0\\)\n\\(\\KL(\\P_\\theta, \\P_\\eta) \\equiv 0 \\iff \\P_\\theta \\equiv \\P_\\eta\\)."
  },
  {
    "objectID": "30-est-method.html#mle",
    "href": "30-est-method.html#mle",
    "title": "5  Ước lượng",
    "section": "5.3 MLE",
    "text": "5.3 MLE\nMaximum Likelihood Estimation\n\n5.3.1 Likelihood\n\nDef 5.3 \\[L_\\theta(x_1,\\ldots,x_n)\\is\n\\P_\\theta(X_1=x_1,\\ldots,X_n=x_n)\n=\n\\prod_{i=1}^n p_\\theta(X_i=x_i)\n.\\]\n\n\n\n5.3.2 Log likelihood\n\nDef 5.4 \\[\n\\ell_\\theta(x_1,\\ldots,x_n)\\is\n\\ln\nL_\\theta(x_1,\\ldots,x_n)\n=\n\\sum_{i=1}^n \\ln p_\\theta(X_i=x_i)\n.\n\\]\n\n\n\n5.3.3 Maximum Likelihood Estimator\n\nDef 5.5 \\[\n\\hat{\\theta}_n \\is\n\\argmax_\\theta\nL_\\theta(x_1,\\ldots,x_n)\n\\equiv\n\\argmax_\\theta\n\\ell_\\theta(x_1,\\ldots,x_n)\n.\n\\]"
  },
  {
    "objectID": "30-est-method.html#mix-model",
    "href": "30-est-method.html#mix-model",
    "title": "5  Ước lượng",
    "section": "5.4 Mix model",
    "text": "5.4 Mix model\n\nDef 5.6 Cho các mô hình gốc \\(X^{(k)}, k= 1,\\ldots,K,\\) lấy biến tiềm ẩn \\(Z\\) trên \\(\\{1,\\ldots,K\\}\\) làm trọng số, ta có mô hình hỗn hợp \\[\nX = \\sum_{k=1}^K\n\\P(Z=k) X^{(k)}\n.\n\\]\n\n\n5.4.1 Giải thuật EM\n\nDef 5.7 (Estimation Maximization) có thể tìm được tham số \\(\\theta\\) của mô hình hỗn hợp Def 5.6.\nGiả sử ta quan sát được \\(X_1=x_1, \\ldots, X_n=x_n\\). Gọi các trọng số tiềm ẩn tương ứng là \\(Z_1=z_1, \\ldots, Z_n=z_n.\\)\nSau khi khởi tạo \\(\\theta = \\theta_0\\) ngẫu nhiên, ta lặp lại 2 bước E, M như sau để cập nhật \\(\\theta_k, k=1,2,\\ldots\\) cho đến khi hội tụ.\n\nEstimate: Ước lượng \\(Z_i\\approx\\omega_i\\is\\E[Z|X_i=x_i, \\theta=\\theta_{k-1}], i=1,\\ldots,n.\\)\nMaximize: Thay \\(Z_i\\) bởi \\(\\omega_i\\) vào công thức likelihood để tối ưu MLE \\(\\theta = \\theta_k\\)"
  },
  {
    "objectID": "30-est-method.html#chuẩn-tính-của-mle",
    "href": "30-est-method.html#chuẩn-tính-của-mle",
    "title": "5  Ước lượng",
    "section": "5.5 Chuẩn tính của MLE",
    "text": "5.5 Chuẩn tính của MLE\n\nDef 5.8 Giả sử log likelihood đối với một quan sát \\(X\\) theo mô hình \\(\\theta\\) là \\(\\ell(\\theta) = \\ln L_1(X,\\theta), \\theta\\in\\Theta\\subset\\R.\\) Giả sử \\(\\ell(\\theta)\\) có đạo hàm bậc hai. Dưới một số điều kiện chuẩn, thông tin Fisher của mô hình được định nghĩa là\n\\[\nI(\\theta)\n= \\V[\\ell^{\\prime}(\\theta)]\n= \\E[(\\ell^{\\prime}(\\theta))^2]\n= -\\E[\\ell^{\\prime\\prime}(\\theta)]\n.\n\\]\n\n\nThm 5.2 Gọi \\(\\theta^*\\in\\Theta\\) là tham số thật cần tìm. Giả sử\n\nCác tham số là indentifiable\nSupport của \\(\\P_\\theta\\) không phụ thuộc vào \\(\\theta\\) với mọi \\(\\theta\\in\\Theta\\)\n\\(\\theta^*\\) không nằm trên biên giới của \\(\\Theta\\)\nThông tin Fisher \\(I(\\theta)\\neq 0\\) xung quanh \\(\\theta^*\\)\nMột số điều kiện kỹ thuật khác\n\nKhi đó, chuỗi \\(\\hat{\\theta}_n^{MLE}\\) thỏa mãn:\n\\[\\hat{\\theta}_n^{MLE} \\xrightarrow[n\\to\\infty]{\\P_{\\theta^*}}\\theta^*\\] \\[\\sqrt{n I(\\theta^*)}\\left(\\hat{\\theta}_n^{MLE}-\\theta^*\\right)\n\\xrightarrow[n\\to\\infty]{(d)\\textrm{ w.r.t.}\\P_{\\theta^*}}\n\\Gaus(0, 1).\\]\nChú ý là điều kiện số 2 dễ bị vi phạm, ví dụ \\(X_i\\iid\\Unif[0, \\theta]\\) mà lại cần tìm tham số \\(\\theta.\\)"
  },
  {
    "objectID": "30-est-method.html#m-estimatior",
    "href": "30-est-method.html#m-estimatior",
    "title": "5  Ước lượng",
    "section": "5.6 M-estimatior",
    "text": "5.6 M-estimatior\n\nDef 5.9 Với mục tiêu ước lượng thuộc tính \\(\\mu^*\\) của xác suất \\(\\P(X)\\), ta tìm một “hàm tổn thất” \\(\\rho(X,\\mu)\\) có giá trị kỳ vọng đạt cực tiểu tại \\(\\mu = \\mu^*:\\) \\[\n\\mathcal{Q}(\\mu)\n\\is \\E_{\\P}[\\rho(X,\\mu)]\n.\n\\]\nNếu quan sát được \\(X_1,\\ldots,X_n\\iid\\P(X),\\) ta ước lượng \\[\n\\mathcal{Q}(\\mu)\n\\approx\n\\mathcal{Q}_n(\\mu)\n\\is\n\\frac{1}{n} \\sum_{i=1}^n{\\rho(X_i,\\mu)}\n.\\]\nKhi đó \\(\\mu^*\\approx\\hat{\\mu}\\) với “M-estimator” \\(\\hat{\\mu}\\) là\n\\[\n\\hat{\\mu}\n\\is\\argmin_{\\mu}\n\\mathcal{Q}_n(\\mu)\n.\n\\]\n\nVí dụ,\n\nvới \\(\\rho(x,\\theta) = -\\ln p_\\theta(x)\\) ta có MLE để ước lượng tham số \\(\\theta^*\\) của mô hình \\(\\P\\)\nvới \\(\\vec x,\\vec\\mu\\in\\R^d\\), dùng \\(\\rho(\\vec x,\\vec\\mu) = \\|\\vec x-\\vec\\mu\\|^2\\) ta ước lượng được \\(\\vec\\mu^*=\\E[\\vec x].\\)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Giáo trình",
    "section": "",
    "text": "John Tsitsiklis, Dimitri Bertsekas, Partick Jaillet. 2022.\n“Probability - the Science of Uncertainty and Data.” MITx.\nhttps://www.edx.org/course/probability-the-science-of-uncertainty-and-data.\n\n\nPhilippe Rigollet, Tyler Maunu, Jan Christian Huetter. 2022.\n“Fundamentals of Statistics.” MITx. https://www.edx.org/course/fundamentals-of-statistics.\n\n\nWasserman, Larry. 2004. All of Statistics : A Concise Course in\nStatistical Inference. New York: Springer. https://archive.org/details/springer_10.1007-978-0-387-21736-9."
  },
  {
    "objectID": "references.html#mitx-18.6501x",
    "href": "references.html#mitx-18.6501x",
    "title": "Giáo trình",
    "section": "MITx 18.6501x",
    "text": "MITx 18.6501x\n“Fundamentals of Statistics” (MITx 18.6501x ) là khóa học của Philippe Rigollet (2022) đại học MIT dạy trên edX.\n\nQuy định\n\nKỳ hạn\n\nExercises and homework: Wednesdays 11:59AM UTC (Wed. 20:59 JST)\nExams (48 hours): Tuesdays 11:59AM UTC(Tue. 20:59 JST)\n\n\n\nThời gian cần thiết\nMỗi tuần khoảng hơn 12 tiếng\n\n5-7 hours on exercises, including 3 hours of lecture clips\n1-2 hours watching recitations\n5-7 hours for weekly problem sets\n\n\n\nTính điểm\nĐiểm thi đậu chứng chỉ là 60% tổng số điểm tối đa.\n\n20% for the lecture exercises (divided equally among the 20 out of 23 lectures)\n20% for the homeworks (divided equally among 10 (out of 12) homeworks)\n18% for the first midterm exam (timed)\n18% for the second midterm exam (timed)\n24% for the final exam (timed)\n\n\n\n\nUnit 1\nÔn lại kiến thức về xác suất “Probability - The Science of Uncertainty and Data” by John Tsitsiklis (2022).\n\n\nUnit 2\nHọc về nền tảng của suy luận (Foundations of Inference).\n\nLecture 3: Mô hình xác suất có số biến hữu hạn (Parametric Statistical Models)\nLecture 4: Dự đoán với số biến hữu hạn và khoảng tự tin (Parametric Estimation and Confidence Intervals) \\({}\\)"
  }
]