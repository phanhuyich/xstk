[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Xác Suất Thống Kê",
    "section": "",
    "text": "$$\n\\def\\as{\\textrm{a.s.}}\n\\def\\Ber{\\text{Ber}}\n\\def\\Bin{\\text{Bin}}\n\\def\\E{\\mathbb{E}}\n\\def\\iid{\\stackrel{iid}{\\sim}}\n\\def\\is{:=}\n\\def\\Gaus{\\mathcal{N}}\n\\def\\P{\\mathbb{P}}\n\\def\\Poi{\\text{Poi}}\n\\def\\R{\\mathbb{R}}\n\\def\\V{\\mathbb{V}}\n\\def\\N{\\mathbb{Z}_+}\n\\def\\TV{\\textrm{TV}}\n\\def\\KL{\\textrm{KL}}\n$$"
  },
  {
    "objectID": "10-proba-intro.html",
    "href": "10-proba-intro.html",
    "title": "1  Xác suất",
    "section": "",
    "text": "Không gian \\(\\Omega\\) là tập hợp chứa tất cả những hiện tượng \\(\\omega\\) có thể xảy ra từ một thí nghiệm. Các tập con của \\(\\Omega\\) là các sự kiện.\nVí dụ xem xét thí nghiệm tung một đồng xu đúng hai lần, quan sát đồng xu rớt xuống nằm ngửa (\\(H\\)) hay sấp (\\(T\\)), ta có \\(\\Omega = \\{HH, HT, TH, TT\\}\\) bao gồm 4 kết quả có thể xảy ra. Sự kiện lần tung đầu tiên ra mặt ngửa của đồng xu là tập hợp \\(\\{HH, HT\\}.\\)\nCho một sự kiện \\(A\\subseteq\\Omega\\), ta nói \\(A\\) xảy ra, hoặc \\(A\\) là đúng, nếu có một hiện tượng \\(\\omega\\in A\\) xảy ra. Sự kiện ngược lại với \\(A\\) là \\(A^c\\is\\Omega-A\\is \\{\\omega\\in\\Omega: \\omega\\notin A\\}\\), tức là “không xảy ra \\(A\\)”. Theo định nghĩa, rõ ràng \\(\\Omega\\) luôn luôn đúng, còn sự kiện rỗng \\(\\emptyset\\equiv\\Omega^c\\) luôn luôn sai. Cho thêm sự kiện \\(B\\), ta có \\(A\\cup B\\) là sự kiện “\\(A\\) hoặc \\(B\\) ít nhất một việc xảy ra”, còn \\(AB\\is A\\cap B\\) là sự kiện “\\(A\\) và \\(B\\) đồng thời xảy ra”.\nChuỗi sự kiện \\(A_1, A_2, \\ldots\\) được gọi là phân ly nếu \\(A_i A_j\\equiv\\emptyset\\) với mọi \\(i\\neq j\\). Khi đó nếu \\(A_1\\cup A_2\\cup\\cdots\\equiv C\\) thì ta nói \\(A_1, A_2, \\ldots\\) là một cách phân hoạch sự kiện \\(C\\)."
  },
  {
    "objectID": "10-proba-intro.html#xác-suất",
    "href": "10-proba-intro.html#xác-suất",
    "title": "1  Xác suất",
    "section": "1.2 Xác suất",
    "text": "1.2 Xác suất\nNếu một xạ ảnh \\(\\P\\) từ không gian các sự kiện \\(A\\subseteq\\Omega\\) lên tập hợp số thực \\(\\R\\) thỏa mãn các điều kiện:\n\n\\(\\P(A)\\geq 0\\quad\\forall A\\)\n\\(\\P(\\Omega) = 1\\)\nNếu chuỗi \\(A_1, A_2, \\ldots\\) phân hoạch \\(C\\) thì \\(\\P(A_1) + \\P(A_2) + \\cdots = \\P(C)\\)\n\nthì ta gọi \\(\\P\\) là một phân phối xác suất hoặc độ đo xác suất.\nCó hai cách cắt nghĩa khái niệm xác suất là tần suất và niềm tin. Theo cách hiểu tần suất thì \\(\\P(A)\\) chính là tỷ lệ số lần sự kiện \\(A\\) xảy ra nếu ta thực hiện thí nghiệm vô số lần. Còn theo cách hiểu niềm tin thì \\(\\P(A)\\) là thước đo mức độ mà một quan sát viên tin tưởng rằng hiện tượng \\(A\\) sẽ xảy ra.\n\nDef 1.1 (Biến ngẫu nhiên) (“random variable”, rv) là một quy tắc ánh xạ \\(X: \\Omega\\to\\R\\) gán cho mỗi hiện tượng \\(\\omega\\) trong không gian \\(\\Omega\\) một số thực \\(X(\\omega)\\).\n\n\nDef 1.2 (Điểm cắt) Điểm cắt tại mức \\(1-\\alpha\\) của biến \\(X\\) là một số \\(q_\\alpha\\) mà \\(\\P(X\\leq q_\\alpha)=1-\\alpha.\\)"
  },
  {
    "objectID": "10-proba-intro.html#độc-lập",
    "href": "10-proba-intro.html#độc-lập",
    "title": "1  Xác suất",
    "section": "1.3 Độc lập",
    "text": "1.3 Độc lập\nHai sự kiện \\(A\\) và \\(B\\) là độc lập nếu \\(\\P(AB)\\equiv \\P(A)\\P(B)\\).\nHai biến \\(X\\) và \\(Y\\) là độc lập nếu hai sự kiện \\(X\\leq x\\) và \\(Y\\leq y\\) là độc lập đối với mọi \\(x,y\\)."
  },
  {
    "objectID": "10-proba-intro.html#tích-suất",
    "href": "10-proba-intro.html#tích-suất",
    "title": "1  Xác suất",
    "section": "1.4 Tích suất",
    "text": "1.4 Tích suất\nTích suất (moment, 積率) thể hiện trọng tâm, độ phân tán, hay độ lệch của phân phối. Tích suất bậc \\(n\\) của biến ngẫu nhiên \\(X\\) với mật độ \\(f(x)\\) là:\n\\[\n\\E[X^n]\\is \\int x^n f(x) dx\n\\]\n\nDef 1.3 (Trung bình) là tích suất bậc 1, tức là \\(\\E[X]\\).\n\nTa có \\[\n\\E[X+Y] \\equiv \\E[X] + E[Y].\n\\]\n\nDef 1.4 (Hiệp phương sai) \\[\\begin{align}\n\\textrm{Cov}[X,Y] &\\is \\E[(X-\\E[X])(Y-\\E[Y])] \\\\\n&\\equiv \\E[XY] - \\E[X]\\E[Y]\n\\end{align}\\]\n\nNếu \\(X\\) và \\(Y\\) độc lập thì \\(\\textrm{Cov}[X,Y] = 0\\).\n\nDef 1.5 (Phương sai) Phương sai, hay phân tán (variance, 分散) là \\[\n\\V[X]\\is\\textrm{Cov}[X,Y]\\equiv\\E[X^2]-\\E^2[X].\n\\]\n\nTa có \\[\n\\V[X+Y] \\equiv \\V[X]+\\V[Y] + 2\\textrm{Cov}[X,Y].\n\\]\n\nDef 1.6 (Hàm tạo tích suất) “Moment geenration function (MGF)” hoặc “Laplace transform” của biến \\(X\\) là \\[\\psi_X(t)\\is\\E[e^{tX}]\\] với \\(t\\in\\R\\).\n\nNếu MGF là “well defined” trên một khoảng mở xung quanh \\(0\\) thì đạo hàm cấp \\(k\\) của \\(\\psi\\) tại \\(0\\) bằng đúng \\(\\E[X^k]\\): \\[\n\\psi^{(k)}(0)\\equiv \\E[X^k].\n\\]"
  },
  {
    "objectID": "10-proba-intro.html#phân-phối",
    "href": "10-proba-intro.html#phân-phối",
    "title": "1  Xác suất",
    "section": "1.5 Phân phối",
    "text": "1.5 Phân phối\nCó một số phân phối xác suất thông dụng.\n\nDef 1.7 (IID) Các biến ngẫu nhiên \\(X_1, X_2, \\ldotp\\) được gọi là iid (“independent and identically distributed”, “độc lập và phân phối giống nhau”) nếu chúng cùng tuân theo duy nhất một phân phối xác suất, và từng cặp biến là độc lập với nhau. Dùng biến \\(X\\) để thể hiện phân phối xác suất chung đó, ta viết \\[X_1,\\ldots,X_n \\iid X.\\]\n\n\nDef 1.8 (Phân phối Bernoulli) \\(X\\sim\\Ber(p)\\) có \\[\n\\P(X=1) = p = 1-\\P(X=0)\n\\] và \\(\\E[X] = p, \\V[X] = p(1-p)\\).\n\n\nDef 1.9 (Phân phối Binomial) \\(X\\sim\\Bin(n, p)\\) với \\(n\\in\\N, p\\in(0,1)\\) mô tả tổng số lần thành công của \\(n\\) thí nghiệm độc lập \\(X_1,\\ldots,X_n \\iid \\Ber(p).\\) Ta có \\[\n\\P(X=k) = \\binom{n}{k}p^{k}(1-p)^{n-k}\n\\] và \\(\\E[X] = np, \\V[X] = np(1-p)\\).\n\n\nDef 1.10 (Phân phối Poisson) \\(X\\sim\\Poi(\\lambda)\\) thường dùng để mô tả số lần \\(k\\) mà sự kiện phát sinh trong một giới hạn cố định, với giả định tần suất phát sinh sự kiện là \\(\\lambda > 0\\) cố định, và các sự kiện phát sinh độc lập. \\[\n\\P(X=k) = e^{-\\lambda}\n\\frac{\\lambda^k}{k!}, \\,k=0,1,2,\\ldots\n\\] và \\(\\E[X] = \\V[X] = \\lambda\\).\n\nKhi \\(n\\) đủ lớn và \\(p\\) đủ nhỏ thì \\(\\Poi(np)\\) gần với \\(\\Bin(n,p)\\).\n\nDef 1.11 (Phân phối Geometric) \\(X\\sim\\text{Geom}(p), p \\in (0,1)\\) có \\[\n\\P(X=k)=p(1-p)^{k-1}, k=1,2,\\ldots\n\\] và \\(\\E[X]=1/p,\\V[X]=(1-p)/p^2.\\)\n\n\nDef 1.12 (Phân phối Exponential) \\(X\\sim\\text{Exp}(\\lambda)\\) dùng để mô tả khoảng cách \\(x\\) giữa hai lần phát sinh của một chuỗi sự kiện kiểu Poisson (hai lần phát sinh sự kiện liên tiếp là độc lập với nhau, và tần suất phát sinh \\(\\lambda>0\\) là cố định). Có \\[\nf(x)={\\lambda}e^{-\\lambda x},x\\in\\R_+\n\\] và \\(\\E[X]=1/\\lambda,\\V[X]=1/\\lambda^2.\\)\n\n\nDef 1.13 (Phân phối Gaussian) \\(X\\sim\\Gaus(\\mu,\\sigma^2)\\) có mật độ \\[\nf(x) =\n\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\nx\\in\\R\n\\] và \\(\\E[X]=\\mu,\\V[X]=\\sigma^2\\)."
  },
  {
    "objectID": "10-proba-intro.html#hội-tụ",
    "href": "10-proba-intro.html#hội-tụ",
    "title": "1  Xác suất",
    "section": "1.6 Hội tụ",
    "text": "1.6 Hội tụ\nCó một số kiểu hội tụ của biến ngẫu nhiên.\n\nDef 1.14 (Hội tụ xác suất) Cho một chuỗi biến ngẫu nhiên \\(X_1,X_2,\\ldotp\\) và một biến ngẫu nhiên \\(X\\).\n\nHội tụ gần tuyệt đối: \\[\nX_n \\xrightarrow[n\\to\\infty]{\\as} X \\iff\n\\P(\\{\\omega\\in\\Omega: X_n(\\omega)\\to X(\\omega)\\}) = 1.\n\\]\nHội tụ theo xác suất: \\[\nX_n \\xrightarrow[n\\to\\infty]{\\P} X \\iff\n\\P(|X_n-X| >\\epsilon)\n\\xrightarrow[n\\to\\infty]{}\n0,\\quad\\forall\\epsilon>0.\n\\]\nHội tụ theo phân phối: \\[\nX_n \\xrightarrow[n\\to\\infty]{(d)} X \\iff\n\\P[X_n(x)\\leq x]\\xrightarrow[n\\to\\infty]{} \\P[X\\leq x]\n\\] tại mọi điểm \\(x\\) mà cdf của \\(X\\) liên tục.\nHội tụ về chuẩn: (asymptotically normal) với phương sai \\(\\sigma^2\\) \\[\n\\sqrt{n}({X}_n-X)\\xrightarrow[n\\to\\infty]{(d)}\n\\Gaus(0,\\sigma^2).\n\\]\n\n\n\nThm 1.1 (Độ mạnh) Xếp theo thứ tự từ mạnh đến yếu:\n\\[\nX_n \\xrightarrow[n\\to\\infty]{\\as} X \\implies\nX_n \\xrightarrow[n\\to\\infty]{\\P} X \\implies\nX_n \\xrightarrow[n\\to\\infty]{(d)} X.\n\\]\nNếu \\(X_n \\xrightarrow[n\\to\\infty]{(d)} X\\), và \\(X\\) có mật độ xác suất, thì \\(X_n \\xrightarrow[n\\to\\infty]{\\P} X\\).\nNếu chuỗi \\(X_n\\) có \\(\\E[X_n]\\xrightarrow[]{} \\mu\\) và \\(\\V[X_n]\\xrightarrow[]{} 0\\) thì \\(X_n\\xrightarrow[]{\\P} \\mu\\).\nNếu \\(X_n\\xrightarrow[n\\to\\infty]{\\P} X\\) thì \\(\\P(a\\leq X_n\\leq b) \\xrightarrow[n\\to\\infty]{} \\P(a\\leq X\\leq b)\\) với mọi khoảng \\([a,b]\\).\n\n\nThm 1.2 (Tổng và tích) Nếu có hai chuỗi biến ngẫu nhiên \\(X_n, Y_n\\) hội tụ gần tuyệt đối hoặc hội tụ theo xác suất về \\(X, Y\\), thì tổng và tích của chúng cũng hội tụ theo cùng kiểu (gần tuyệt đối, hoặc theo xác suất) về tổng \\(X+Y\\) hoặc tích \\(XY\\) tương ứng.\n\n\nThm 1.3 (Slutsky) Nếu \\(Y_n \\xrightarrow[]{\\P} y\\), \\(y\\) là một số thực cố định thì có thể nới lỏng điều kiện đối với \\(X_n\\) thành hội tụ theo phân phối.\n\n\nThm 1.4 (Ánh xạ liên tục) (Continuous mapping) Nếu \\(X_n\\xrightarrow[n\\to\\infty]{\\as/\\P/(d)} X\\) thì đối với mọi hàm \\(f\\) liên tục:\n\n\\(f(X_n)\\xrightarrow[n\\to\\infty]{\\as/\\P/(d)} f(X)\\).\n\\(\\E[f(X_n)]\\xrightarrow[n\\to\\infty]{}\\E[f(X)]\\) nếu \\(f\\) còn bị chặn.\n\n\n\nThm 1.5 (Đại đa số (Law of Large Numbers)) Cho \\(n\\) biến iid \\(X_1, X_2,\\ldotp,X_n\\) có chung \\(\\E[X_i]=\\mu<\\infty\\). Khi đó: \\[\\bar{X}_n\\is\\frac{1}{n}\\sum_{i=1}^n{X_i}\n\\xrightarrow[n\\to\\infty]{\\P,\\,\\as}\\mu.\n\\]\n\n\nThm 1.6 (Hội tụ trung tâm (Central Limit)) Giả sử thêm là \\(\\V[X_i]=\\sigma^2<\\infty\\). Khi đó \\[\n\\sqrt{n}(\\bar{X}_n-\\mu)\n\\xrightarrow[n\\to\\infty]{(d)}\n\\Gaus(0,\\sigma^2).\n\\]\n\n\nThm 1.7 (Bất đẳng thức Hoefding) Nếu có một khoảng cố định \\([a,b]\\) gần như tuyệt đối (almost surely) chứa các biến \\(X_i (i=1,2,\\ldots,n)\\) thì\n\\[\n\\P[|\\bar{X}_n-\\mu|\\geq\\epsilon]\\leq\n2e^{-\\frac{2n\\epsilon^2}{(b-a)^2}},\\quad\\forall\\epsilon>0.\n\\]\n\n\nThm 1.8 (Phương pháp Delta) Giả sử chuỗi \\((\\theta_n)_{n\\geq 1}\\) chuẩn tiến với phương sai \\(\\sigma^2\\) về một điểm \\(\\theta\\in\\R\\). Giả sử \\(g:\\R\\to\\R\\) có vi phân \\(g'\\) liên tục tại \\(\\theta\\). Khi đó, \\[\n\\sqrt{n}(g(\\theta_n)-g(\\theta))\n\\xrightarrow[n\\to\\infty]{(d)}\n\\Gaus(0,(g'(\\theta))^2\\sigma^2)\n\\]"
  },
  {
    "objectID": "20-stat-intro.html",
    "href": "20-stat-intro.html",
    "title": "2  Thống kê",
    "section": "",
    "text": "Trên không gian đo được \\(E\\subseteq\\R\\) ta quan sát các mẫu \\(X_1,\\ldots,X_n\\iid\\P\\). Với tập tham số \\(\\Theta\\) ta xây dựng bộ độ đo xác suất \\((\\P_\\theta)_{\\theta\\in\\Theta}\\) để mô phỏng \\(\\P\\) .\nNếu tồn tại \\(\\theta\\in\\Theta\\) để \\(\\P_\\theta\\equiv\\P\\) thì ta nói mô hình “hợp lệ” (well cpecified).\nNếu từ tập \\(\\Theta\\), ánh xạ \\(\\theta\\mapsto\\P_{\\theta}\\) là đơn tính thì ta nói \\(\\theta\\) là “có thể nhận dạng” (identifiable).\nNếu \\(\\Theta\\subseteq\\R^d\\) thì mô hình được nói có số biến hữu hạn (parametric model)."
  },
  {
    "objectID": "20-stat-intro.html#ước-lượng",
    "href": "20-stat-intro.html#ước-lượng",
    "title": "2  Thống kê",
    "section": "2.2 Ước lượng",
    "text": "2.2 Ước lượng\nThống kê lượng (statistic) \\(\\theta\\) là bất cứ hàm số nào có thể đo được (measurable function) trên tập dữ liệu đối tượng \\(X_i\\).\nĐánh giá (estimator) \\(\\theta_n\\) đối với mục tiêu thống kê \\(\\theta\\) là một thống kê khác không phụ thuộc vào \\(\\theta\\).\nĐánh giá được gọi là nhất quán (consistent) nếu nó hội tụ về mục tiêu (Def 1.14).\nĐộ lệch (bias) giữa đánh giá \\(\\theta_n\\) với mục tiêu \\(\\theta\\) là \\[\\textrm{bias}_{\\theta}({\\theta}_n) \\is \\E[\\theta_n] - \\theta.\\]\nSai số bậc 2 (quadratic risk, mean squared error) giữa đánh giá \\(\\theta_n\\) với mục tiêu \\(\\theta\\) là \\[\n\\textrm{MSE}(\\theta_n)\\is\\E[(\\theta_n-\\theta)^2]\n\\equiv\n\\textrm{bias}_{\\theta}(\\theta_n)^2\n+\n\\V[\\theta_n]\n\\] bao hàm cả độ lệch và độ nhiễu của đánh giá."
  },
  {
    "objectID": "20-stat-intro.html#khoảng-tin-cậy",
    "href": "20-stat-intro.html#khoảng-tin-cậy",
    "title": "2  Thống kê",
    "section": "2.3 Khoảng tin cậy",
    "text": "2.3 Khoảng tin cậy\nVới mô hình thống kê \\((E,(\\P_\\theta)_{\\theta\\in\\Theta})\\) xây dựng dựa trên quan sát \\(X_1,\\ldots,X_n\\), giả sử số \\(\\alpha\\in(0,1).\\) Khoảng tin cậy (confidence interval) cấp \\(1-\\alpha\\) đối với \\(\\theta\\) là một khoảng ngẫu nhiên \\(\\mathcal{I}\\) (phụ thuộc vào \\(X_1,\\ldots,X_n\\), không phụ thuộc vào \\(\\theta\\)), mà xác suất \\(\\mathcal{I}\\) có chứa \\(\\theta\\) là đủ cao: \\[\\P_\\theta[\\mathcal{I}\\ni\\theta]\\geq 1-\\alpha,\\quad\\forall\\theta\\in\\Theta.\\]\nNếu \\[\\lim_{n\\to\\infty}\\P_\\theta[\\mathcal{I}\\ni\\theta]\\geq 1-\\alpha,\\quad\\forall\\theta\\in\\Theta\\] thì ta gọi \\(\\mathcal{I}\\) là khoảng tin cậy tiệm cận cấp \\(1-\\alpha\\) đối với \\(\\theta\\)."
  },
  {
    "objectID": "20-stat-intro.html#kiểm-định",
    "href": "20-stat-intro.html#kiểm-định",
    "title": "2  Thống kê",
    "section": "2.4 Kiểm định",
    "text": "2.4 Kiểm định"
  },
  {
    "objectID": "30-est-method.html",
    "href": "30-est-method.html",
    "title": "3  Ước lượng",
    "section": "",
    "text": "Chiến lược ước lượng phân phối thật (true distribution)\nVới mô hình thống kê \\((E,(\\P_\\theta)_{\\theta\\in\\Theta})\\) xây dựng dựa trên quan sát iid rv \\(X_1,\\ldots,X_n\\) trên tập mẫu \\(E\\) và bộ tham số \\(\\Theta\\) . Ngầm định tồn tại tham số thật \\(\\theta^*\\in\\Theta\\) để \\(X_1\\sim\\P_{\\theta^*}\\) ."
  },
  {
    "objectID": "30-est-method.html#tổng-biến-động",
    "href": "30-est-method.html#tổng-biến-động",
    "title": "3  Ước lượng",
    "section": "3.1 Tổng biến động",
    "text": "3.1 Tổng biến động\n\nDef 3.1 (Khoảng cách) tổng biến động (total variation distance) giữa hai độ đo xác suất \\(\\P_\\theta\\) và \\(\\P_\\eta\\) là\n\\[\n\\TV(\\P_\\theta,\\P_{\\eta})\n=\n\\max_{A\\subset E}{\\mid\\P_\\theta(A)-\\P_\\eta(A)\\mid}.\n\\]\n\n\nThm 3.1 (Công thức tính) Nếu tập mẫu \\(E\\) là rời rạc (discrete: countable or finite), xác suất \\(\\P_\\theta,\\P_{\\eta}\\) có hàm khối lần lượt là \\(p_\\theta,p_{\\eta}\\) thì \\[\n\\TV(\\P_\\theta,\\P_{\\eta}) =\n\\frac{1}{2}\n\\sum_{x\\in E}\\mid p_\\theta(x) - p_\\eta(x)\\mid.\n\\]\nNếu tập mẫu \\(E\\) là liên tục (continuous), xác suất \\(\\P_\\theta, \\P_{\\eta}\\) có mật độ lần lượt là \\(f_\\theta, f_{\\eta}\\) thì \\[\n\\TV(\\P_\\theta,\\P_{\\eta}) =\n\\frac{1}{2}\n\\int_{E}\\mid f_\\theta(x) - f_\\eta(x)\\mid dx.\n\\]"
  },
  {
    "objectID": "30-est-method.html#phân-kỳ-kl",
    "href": "30-est-method.html#phân-kỳ-kl",
    "title": "3  Ước lượng",
    "section": "3.2 Phân kỳ KL",
    "text": "3.2 Phân kỳ KL\n\nDef 3.2 (Phân kỳ KL) (KL divergence) Ký hiệu \\(f\\) là mật độ hoặc hàm khối xác suất:\n\\[\n\\KL(\\P_\\theta, \\P_\\eta) \\is\n\\E_\\theta\\left[ \\ln\\frac{f_\\theta(x)}{f_\\eta(x)} \\right]\n=\n\\E_\\theta\\left[ \\ln{f_\\theta(x)} \\right]\n-\n\\E_\\theta\\left[ \\ln{f_\\eta(x)} \\right]\n.\n\\]\n\n\nProposition 3.1 (Đặc điểm) Phân kỳ KL thỏa mãn 2/4 đặc điểm của “khoảng cách”:\n\n\\(\\KL(\\P_\\theta, \\P_\\eta) \\geq 0\\)\n\\(\\KL(\\P_\\theta, \\P_\\eta) \\equiv 0 \\iff \\P_\\theta \\equiv \\P_\\eta\\)."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Tóm tắt",
    "section": "",
    "text": "$$\n\\def\\as{\\textrm{a.s.}}\n\\def\\Ber{\\text{Ber}}\n\\def\\Bin{\\text{Bin}}\n\\def\\E{\\mathbb{E}}\n\\def\\iid{\\stackrel{iid}{\\sim}}\n\\def\\is{:=}\n\\def\\Gaus{\\mathcal{N}}\n\\def\\P{\\mathbb{P}}\n\\def\\Poi{\\text{Poi}}\n\\def\\R{\\mathbb{R}}\n\\def\\V{\\mathbb{V}}\n\\def\\N{\\mathbb{Z}_+}\n\\def\\TV{\\textrm{TV}}\n\\def\\KL{\\textrm{KL}}\n$$"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Giáo trình",
    "section": "",
    "text": "John Tsitsiklis, Dimitri Bertsekas, Partick Jaillet. 2022.\n“Probability - the Science of Uncertainty and Data.” MITx.\nhttps://www.edx.org/course/probability-the-science-of-uncertainty-and-data.\n\n\nPhilippe Rigollet, Tyler Maunu, Jan Christian Huetter. 2022.\n“Fundamentals of Statistics.” MITx. https://www.edx.org/course/fundamentals-of-statistics.\n\n\nWasserman, Larry. 2004. All of Statistics : A Concise Course in\nStatistical Inference. New York: Springer. https://archive.org/details/springer_10.1007-978-0-387-21736-9."
  },
  {
    "objectID": "references.html#mitx-18.6501x",
    "href": "references.html#mitx-18.6501x",
    "title": "Giáo trình",
    "section": "MITx 18.6501x",
    "text": "MITx 18.6501x\n“Fundamentals of Statistics” (MITx 18.6501x ) là khóa học của Philippe Rigollet (2022) đại học MIT dạy trên edX.\n\nQuy định\n\nKỳ hạn\n\nExercises and homework: Wednesdays 11:59AM UTC (Wed. 20:59 JST)\nExams (48 hours): Tuesdays 11:59AM UTC(Tue. 20:59 JST)\n\n\n\nThời gian cần thiết\nMỗi tuần khoảng hơn 12 tiếng\n\n5-7 hours on exercises, including 3 hours of lecture clips\n1-2 hours watching recitations\n5-7 hours for weekly problem sets\n\n\n\nTính điểm\nĐiểm thi đậu chứng chỉ là 60% tổng số điểm tối đa.\n\n20% for the lecture exercises (divided equally among the 20 out of 23 lectures)\n20% for the homeworks (divided equally among 10 (out of 12) homeworks)\n18% for the first midterm exam (timed)\n18% for the second midterm exam (timed)\n24% for the final exam (timed)\n\n\n\n\nUnit 1\nÔn lại kiến thức về xác suất “Probability - The Science of Uncertainty and Data” by John Tsitsiklis (2022).\n\n\nUnit 2\nHọc về nền tảng của suy luận (Foundations of Inference).\n\nLecture 3: Mô hình xác suất có số biến hữu hạn (Parametric Statistical Models)\nLecture 4: Dự đoán với số biến hữu hạn và khoảng tự tin (Parametric Estimation and Confidence Intervals) \\({}\\)"
  }
]