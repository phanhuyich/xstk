# Bayesian

## Phương pháp

:::{#def-bayesian-method}
### Bayesian method
Với dữ liệu $X_1,\ldots,X_n,$
ta
ước lượng tham số $\theta$ cho mô hình xác suất qua các bước:

1. Gán xác suất tiên nghiệm (prior) $\pi(\theta)$ cho tham số $\theta\in\Theta.$
2. Chọn xác suất $f(X|\theta)$ phụ thuộc vào $\theta,$
gọi MLE (@def-mle) là $L_n$
3. Tính xác suất hậu nghiệm (posterior) theo Bayes @thm-bayes:

$$
\begin{split}
\pi(\theta|X_1,\ldots,X_n)
&\propto
L_n(X_1,\ldots,X_n|\theta)
\pi(\theta),
\quad\theta\in\Theta
.
\end{split}
$$
:::

## Loại prior

:::{#def-conjugate-prior}
### Conjugate prior
Nếu xác suất tiền nghiệm và xác suất hậu nghiệm thuộc cùng một hệ xác suất, ta nói xác suất tiền nghiệm là liên hợp đối với mô hình.
:::

:::{#exm-conjugate-prior}
Beta là xác suất liên hợp tiền nghiệm đối với mô hình Bernoulli $\Ber$, nhị thức $\Bin$ và hình học $\Geom.$
:::

:::{#def-non-informative-prior}
### Non informative prior
Nếu ta không có thông tin tiền nghiệm gì về tham số
$\theta\in\Theta=[a, b]$ thì có thể dùng
phân phối đồng đều $\Unif[a,b]$ làm xác suất tiền nghiệm.
:::

:::{#def-improper-prior}
### Improper prior
Nếu
hàm $\pi:\Theta\to[0,+\infty)$ là đo được (measurable)
nhưng không khả tích toàn phần trên $\Theta$
thì ta nói $\pi$ là improper prior.
:::

:::{#def-jeffreys-prior}
### Jeffreys prior
$$\pi_J(\theta)\propto\sqrt{\det I(\theta)}
$$
với $I(\theta)$ là thông tin Fisher (@def-fisher-info)
của mô hình thống kê cho
$X_1,\ldots,X_n.$
:::

:::{#exm-jeffreys-prior}
- Thí nghiệm $\Ber(p), p\in(0,1)$ có
$$\pi_J(p)\propto\frac{1}{\sqrt{p(1-p)}}\propto\Beta{\frac{1}{2}}{\frac{1}{2}}
.$$
- Thí nghiệm $\Gaus{\mu}{\sigma^2}, (\mu,\sigma^2)\in\R\times\R_+$ có
$\pi_J(\mu,\sigma^2)\propto \sigma^{-3}$ là improper prior.
:::
